{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Lab4_Adv_Classification_Exercises_II.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"vpABWMWB3p5Z"},"source":["# Topic 1. Machine Learning \n","\n","\n","## Supervised, unsupervised methods\n","\n","In this lab we will exercise different aspects related to the solution to initial steps of ML problem solving. In particular: \n","\n","1- Methods for reading and manipulating real-world datasets (pandas library)\n","\n","2- Methods for problem visualization and analysis  (seaborn library)\n","\n","3- Supervised classification problems \n","\n","4- Unsupervised classification problems  \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qI5qphlk3p5b"},"source":["We import all the libraries required for the exercises"]},{"cell_type":"code","metadata":{"id":"g_-MKKWb3p5h","executionInfo":{"status":"ok","timestamp":1601467001211,"user_tz":-120,"elapsed":1441,"user":{"displayName":"Julen Etxaniz Aragoneses","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilpYDAmorj7KFdjK26TlsyH_HhFWhLqmESeKoCGsI=s64","userId":"06956422670240182492"}}},"source":["import numpy as np\n","import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_regression\n","from sklearn.linear_model import LinearRegression, Lasso, Ridge\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import binarize\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.cluster import KMeans\n","from mpl_toolkits.mplot3d import axes3d  \n","from sklearn import preprocessing\n","from sklearn.pipeline import Pipeline"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGOann4e3p5v"},"source":["##  Reading and manipulating datasets with pandas "]},{"cell_type":"markdown","metadata":{"id":"ZPcaHt3f3p5w"},"source":["We will use the Parkinsons Telemonitoring Data Set available from https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/telemonitoring/\n","    \n","    This dataset contains 16 biomedical voice measurements from 42 people with early-stage Parkinson's disease. \n","    \n","    The main aim of the data is to predict the motor and total UPDRS scores ('motor_UPDRS' and 'total_UPDRS') from the 16 voice measures. \n","\n","    This can be seen as a regression problem. "]},{"cell_type":"markdown","metadata":{"id":"dDvDF2Kn3p5y"},"source":["### Download the dataset  and open using the following pandas commands. Pandas is an extensively used python library: https://pandas.pydata.org/"]},{"cell_type":"code","metadata":{"id":"Dj6DorMy3p5z"},"source":["# The dataset is read\n","df = pd.read_csv('parkinsons_updrs.data')\n","\n","# The columns of the dataset are printed. These columns include the features and \n","# the target variables 'motor_UPDRS' and 'total_UPDRS') \n","print(df.columns)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKbNqupM3p59"},"source":["# There are 42 subjects. We will use data for the first one\n","indices_subject_1 = df['subject#']==1\n","\n","# Records of subject_1\n","df_subject_1 = df[indices_subject_1]\n","\n","# Records of the dataframe are transformed to a matrix and we print its shape\n","data = df_subject_1.values\n","print('The shape of the matrix is ',data.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pu7aP9rG3p6J"},"source":["## Visualizing data with seaborn\n"]},{"cell_type":"markdown","metadata":{"id":"MX6bBSep3p6O"},"source":["### seaborn is a python library that allows the exploration of data. A brief overview of the functionalities of seaborn can be accessed from: https://seaborn.pydata.org/examples/index.html"]},{"cell_type":"code","metadata":{"id":"lvtJYh9_3p6Q"},"source":["# We visualize the relationships between variables in the Parkinson dataset\n","sns.pairplot(df)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VZN9T_MK3p6a"},"source":["### We visualize the distribution of the variables, ordered depending the variance they have"]},{"cell_type":"code","metadata":{"id":"7cAVVVtz3p6b"},"source":["order = df.std().sort_values().index\n","fig = plt.figure(figsize=(12,6))\n","#chart = sns.lvplot(data=df, order=order, scale=\"linear\")\n","chart = sns.boxenplot(data=df, order=order, scale=\"linear\")\n","chart.set_xticklabels(chart.get_xticklabels(),rotation=45)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MeUjKQCV3p6n"},"source":["### We scale variables for improved visualization"]},{"cell_type":"code","metadata":{"id":"_thM5w753p6q"},"source":["df_sca = df - df.min()\n","df_sca /= df_sca.max()\n","\n","fig = plt.figure(figsize=(12,6))\n","#chart = sns.lvplot(data=df_sca, order=order, scale=\"linear\")\n","chart = sns.boxenplot(data=df_sca, order=order, scale=\"linear\")\n","chart.set_xticklabels(chart.get_xticklabels(),rotation=45)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrBXB1V23p62"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SufHNZqY3p6_"},"source":["# Exercise 1\n","\n","1.1) Using only data from the first subject, create train and test datasets to predict the total_UPDRS score using the following features: ['Jitter(%)', 'Jitter(Abs)', 'Jitter:RAP', 'Jitter:PPQ5', 'Jitter:DDP','Shimmer', 'Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5','Shimmer:APQ11', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']\n","      \n","1.2) Use a linear regressor to predict the response variable in the test data from a model learned in the train data.\n","\n","1.3) Use a random forest regressor to predict the response variable in the test data from a model learned in the train data.\n","\n","1.4) Use a Gaussian process regressor to predict the response variable in the test data from a model learned in the train data.\n","\n","1.5) Use the seaborn and matplotlib libraries to visualize the median_absolute_error of the three regressor algorithms used in exercises 1.2, 1.3, and 1.4. \n","Hints: Use https://seaborn.pydata.org/generated/seaborn.barplot.html or https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.bar.html\n","\n"]},{"cell_type":"markdown","metadata":{"id":"J7bGj5bx3p7A"},"source":["### Answer to 1.1)"]},{"cell_type":"code","metadata":{"id":"KkdBjavD3p7D","outputId":"28bf6e06-b6d6-4b70-ff13-5b35c757a8b6"},"source":["# From the data, we select the response variable that we are going to model\n","# It is the total_UPDRS score\n","target = XXX\n","\n","# The 16 variables that measure the voice will be used as features. \n","features = XXX\n","\n","\n","# We divide the dataset for the first subject in training and test data. Even rows are in the train set \n","# and odd rows in the test set. \n","\n","# Train set \n","train_features = XXX\n","train_target = XXX\n","train_n_samples = XXX\n","\n","# Test set\n","test_features = XXX\n","test_target = XXX\n","test_n_samples = XXX"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'XXX' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fdecf2de05c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# From the data, we select the response variable that we are going to model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# It is the total_UPDRS score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The 16 variables that measure the voice will be used as features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'XXX' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"afSNQzjV3p7M"},"source":["### Answer to 1.2)"]},{"cell_type":"code","metadata":{"id":"7lfudyFl3p7O"},"source":["regressor = XXX\n","regressor.fit(XXX,XXX)\n","predicted_test_target = XXX"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EDB7Ilbi3p7b"},"source":["###  Answer to 1.3)"]},{"cell_type":"code","metadata":{"id":"OTVVTJv03p7c"},"source":["rf_regressor = XXX\n","rf_regressor.XXX\n","rf_predicted_test_target = XXX\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M1BrM_Q-3p7p"},"source":["### Answer to 1.4)"]},{"cell_type":"code","metadata":{"id":"Ge-7aMez3p7r"},"source":["gp_regressor = XXX\n","gp_regressor.fit(XXX,XXX)\n","gp_predicted_test_target = XXX"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OmSto4VF3p7z"},"source":["### Answer to 1.5)"]},{"cell_type":"code","metadata":{"id":"ffpVQzOd3p73"},"source":["width = 1.0\n","n_regressors = 3\n","error_lr = XXX\n","error_rf = XXX\n","error_gp = XXX\n","\n","error_values = [error_lr,error_rf,error_gp]\n","ind = np.arange(n_regressors)+1\n","\n","p1 = plt.bar(XXX, XXX, width)\n","\n","\n","plt.ylabel('median absolute error')\n","plt.title('Errors produced by the three regressors')\n","plt.xticks(ind, ('LR', 'RF', 'GR',))\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvLXCjoQ3p8A"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gbuGOqye3p8I"},"source":[" ## yacht_hydrodynamics dataset "]},{"cell_type":"markdown","metadata":{"id":"YEVDngRY3p8K"},"source":["We download the yacht_hydrodynamics dataset from https://archive.ics.uci.edu/ml/datasets/Yacht+Hydrodynamics\n","\n","The goal of this dataset is the prediction of residuary resistance of sailing yachts from a number of features.  Essential inputs include the basic hull dimensions and the boat velocity. \n","\n","This can be approached as a regression problem"]},{"cell_type":"code","metadata":{"id":"sTgpnwIr3p8L"},"source":["\n","# https://archive.ics.uci.edu/ml/datasets/Yacht+Hydrodynamics\n","data = np.loadtxt('yacht_hydrodynamics.data')\n","\n","# The Pandas dataframe is created\n","df = pd.DataFrame(data,columns=['Long. position', 'Prismatic coef.', 'LD ratio', 'BD ratio', \n","                                'LB ratio', 'Froude numb.', 'Resistance' ])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggK25jEL3p8X"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ob7b4VVF3p8h"},"source":["# Visualization of the dataset\n","sns.pairplot(df)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Trcm2px53p8q"},"source":["## Exercise 2\n","\n","2.1) Create train and test datasets from the ship data\n","\n","2.2) Use kmeans to separate the train data into five clusters\n","\n","2.3) Use a dimensionality reduction method to visualize the clusters in three dimensions\n","Hint: Use a different color to visualize each of the five clusters\n","    \n","2.4) Create a pipeline that selects two variables and applies linear regressor to predict the ship resistance\n","\n","2.5) Visualize the original resistance data versus the predictions made by the pipeline"]},{"cell_type":"markdown","metadata":{"id":"cBTk3PfO3p8s"},"source":["### Answer to 2.1)"]},{"cell_type":"code","metadata":{"id":"qyg7shrm3p8v"},"source":["yach_features = XXX\n","yach_target = XXX\n","\n","# We split the data into two sets, training and test\n","\n","yach_train_features = XXX\n","yach_train_target = XXX\n","yach_train_n_samples = XXX\n","\n","yach_test_features = XXX\n","yach_test_target = XXX\n","yach_test_n_samples = XXX\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3fwE81TO3p86"},"source":["### Answer to 2.2)"]},{"cell_type":"code","metadata":{"id":"izBdb8YR3p8-"},"source":["kmeans = XXX\n","kmeans.fit(XXX)\n","yach_train_clusters = XXX\n","print(yach_train_clusters)\n","#test_clusters = kmeans.predict(yach_test_features)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YgLV-Y1L3p-G"},"source":["### Answer to 2.3)"]},{"cell_type":"code","metadata":{"id":"5ocLjUU53p-H"},"source":["colors = 'brgmk'\n","n_components = 3\n","pca = XXX\n","pca.XXX\n","\n","dim3_yach_train_data = XXX\n","\n","\n","fig = plt.figure(figsize=(8, 12))\n","ax = fig.add_subplot(111, projection='3d')\n","\n","for i,c in enumerate(colors):\n","    #print(i,c)\n","\n","    index_cluster = np.where(yach_train_clusters==XXX)   \n","    x_vals = dim3_yach_train_data[index_cluster,0]\n","    y_vals = XXX\n","    z_vals = XXX\n","    # Plot the values\n","    ax.scatter(XXX, y_vals, z_vals, c = c, marker='o')\n","    #print(index_cluster)\n","\n","ax.set_xlabel('X-axis')\n","ax.set_ylabel('Y-axis')\n","ax.set_zlabel('Z-axis')\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e3KVJqdt3p-N"},"source":["### Answer to 2.4)"]},{"cell_type":"code","metadata":{"id":"or3gqVRP3p-O"},"source":["feature_selector = XXX\n","linear_regressor = XXX\n","\n","yach_pipeline = XXX\n","yach_pipeline.XXX\n","\n","yach_pipeline_test_prediction = yach_pipeline.XXX\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbVdfi-V3p-S"},"source":["### Answer to 2.5)"]},{"cell_type":"code","metadata":{"id":"FxGTJblF3p-T"},"source":["\n","plt.plot(XXX,XXX,'r.')\n","plt.xlabel('Response variable')\n","plt.ylabel('Prediction')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PczuHNRC3p-d"},"source":["## Exercise 3\n","\n","Moving forward to a real classification problem,\n","\n","3.1) Fetch a real database from the uci dataset (https://archive.ics.uci.edu/ml/datasets.php)\n","\n","3.2) Define and fit a classifier using the data.\n","\n","3.3) Use cross-validation to estimate the accuracy, recall, and precision of the classifier.\n","\n","3.4) Use a pre-processing method to transform the data before feeding it to the classifier\n","\n","3.5) Create a Pipeline which includes (at least) one preprocessing method, and a classifier.\n","\n","3.6) Apply the pipeline to the data.\n","\n","3.7) Use Tpot to automatically generate a pipeline"]},{"cell_type":"code","metadata":{"id":"GTGWSNTF3p-d"},"source":[""],"execution_count":null,"outputs":[]}]}