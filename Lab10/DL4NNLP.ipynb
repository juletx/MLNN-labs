{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Table of Content\n",
    "----\n",
    "\n",
    "<a href='#section1'> 1. Introduction</a>\n",
    "\n",
    "__PART 1: Sentiment Analysis__\n",
    "\n",
    "<a href='#section2'>2. Text Representation in DL</a>\n",
    "> <a href='#section2_load_data'>2.1 Load data</a>\n",
    "\n",
    "> <a href='#section2_examin_data'>2.2 Examine the dataset</a>\n",
    "\n",
    "> <a href='#section2_one_hot'>2.3 One-hot encoding of the data</a>\n",
    "\n",
    "> <a href='#section2_word_index'>2.4 Inspect created word-index</a>\n",
    "\n",
    "<a href='#section3'>3. What's going on inside a MLP</a>\n",
    "\n",
    "<a href='#section4'>4. MLP in Keras</a>\n",
    "\n",
    "> <a href='#section4_model_optimization'>4.1. Model Optimization</a>\n",
    "\n",
    "<a href='#section5'>5. Other models for text</a>\n",
    "\n",
    "> <a href='#section5_padding'>5.1 Padding sequences </a>\n",
    "\n",
    "> <a href='#section5_lstm'>5.2 Build a LSTM model in few lines</a>\n",
    "\n",
    "> <a href='#section5_cnn'>5.3 1D CNN for texts (optional)</a>\n",
    "\n",
    "\n",
    "__PART 2: Word Embeddings__\n",
    "\n",
    "<a href='#section6'>6. Set up</a>\n",
    "\n",
    "<a href='#section7'>7. Task 1: Semantically similar/related words</a>\n",
    "\n",
    "<a href='#section8'>8. Task 2: Semantic orientation</a>\n",
    "\n",
    "<a href='#section9'>9. Task 3: Analogy</a>\n",
    "\n",
    "<a href='#section10'>10. Visualization (optional)</a>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. Introduction\n",
    "\n",
    "This lab session is organized in two main parts. The first part is devoted to build a classifier for textual input. In the second part we will work with word embeddings to understand their usefulness.  \n",
    "\n",
    "### Part 1: Sentiment Analysis (1h approx)\n",
    "\n",
    "In first part we will implement a series models for __sentence classification__ using Keras and TensorFlow. Given a sentence our model will predict if it is a positive or negative piece of texts. The dataset we are going to use ranges the polarity annotation from 0 to 5, where 0 denotes extremelt negative sentiment,  and 5  is the most  positive. \n",
    "\n",
    "Nevertheless, for this lab we will simplify the task, and we will translate the 5-way classification task (actually [0-5] regression task) into 2-way classification task (0 $\\rightarrow$ _negative,_ ;1 $\\rightarrow$ positive),\n",
    "\n",
    "All in all, the main __objectives__ of this lab session for this part are the following: \n",
    "- How to represent text as input of neural network models (the _one-hot econding_).\n",
    "- Understant the mechanics of a Multi-Layer Perceptron (a.k.a Feedforward layer) with TensorFlow.\n",
    "- Learn how to build, train and evaluate suitable for text model in Keras.\n",
    "\n",
    "-----\n",
    "\n",
    "Optionally, once you finished the whole lab, you could explore following things:\n",
    "- Explore hyperparameters like:\n",
    "  - Optimizers: SGD, ADAGRAD, etc.\n",
    "  - Learning Rates\n",
    "  - Regularization (more on this next lab)\n",
    "- Plot learning curves for model selection\n",
    "\n",
    "----\n",
    "\n",
    "### Part 2: Word Embeddings (1h approx)\n",
    "\n",
    "In the second part of the session  we will learn how to work with word embeddings. We show that applying simple techniques we can implement very cool stuff. \n",
    "\n",
    "This part is divided in many parts that in most of the cases do not need code implementation. Hopefully, you would complete the assignment in a short time and have great fun too. \n",
    "\n",
    "The main __objective__ of this part is to learn about some interesting task that can be acomplish with word embeddings:\n",
    "\n",
    "- __Task 1__: Word similarity and relatedness\n",
    "- __Task 2__: Score semantically the words\n",
    "- __Task 3__: Do analogies, like _Man is to King like Woman is to Queen_\n",
    "\n",
    "------\n",
    "\n",
    "## Exercise Index\n",
    "__Part 1 exercises__:\n",
    "\n",
    "<a href='#exercise1'>Exercise 1: Most vs leas frequent words</a>\n",
    "\n",
    "<a href='#exercise2'>Exercise 2: Coding MLP</a>\n",
    "\n",
    "<a href='#exercise3'>Exercise 3: Vocab size effect</a>\n",
    "\n",
    "<a href='#exercise4'>Exercise 4: Model optimization</a>\n",
    "\n",
    "<a href='#exercise5'>Exercise 5: One-hot encoding vs Embedding encoding</a>\n",
    "\n",
    "<a href='#exercise6'>Exercise 6: Building a LSTM</a>\n",
    "\n",
    "<a href='#exercise7'>Exercise 7 (optional): 1D CNN for text</a>\n",
    "\n",
    "-----\n",
    "__Part 2 exercises__:\n",
    "\n",
    "<a href='#exercise8'>Exercise 8: Word similarity/relatedness</a>\n",
    "\n",
    "<a href='#exercise9'>Exercise 9: Semantics orientation</a>\n",
    "\n",
    "<a href='#exercise10'>Exercise 10: Analogy</a>\n",
    "\n",
    "<a href='#exercise11'>Exercise 11: Visualization (optional)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. Text Representation in DL\n",
    "\n",
    "Once data is loaded the next step is to preprocess it to obtain the vectorized form (i.e. the process of transforming text into numeric tensors), which basically consist of:\n",
    "\n",
    "- Tokenization, tipically segment the text into words. (Alternatively, we could segment text into characters, or extract n-grams of words or characters.)\n",
    "- Definition of the dictionary index and vocabulary size (in this case we set to 1000 most frequent words)\n",
    "- Transform each word into a vector. \n",
    "\n",
    "\n",
    "There are multiple ways to vectorize tokens. The main two are the following: ___One-hot encoding___ and ___word embedding___. In the first part of the lab, we'll make use of the basic tools provided by Keras to obtain __the one-hot encoding__. \n",
    "\n",
    "\n",
    "-----\n",
    "\n",
    "<a id='section2_load_data'></a>\n",
    "### Load data\n",
    "\n",
    "We provide the __Movie Review from Rottern Tomatoes dataset (MRRT)__ dataset for sentiment analysis, which the original can be downloaded from [here](https://www.cs.cornell.edu/people/pabo/movie-review-data/). We are using version 1.0. Please, __download__ the dataset ready for the lab from here:\n",
    "\n",
    "- Download data from [this link](https://www.dropbox.com/s/kej8qc13fhgdd8c/data.tar.bz2?dl=0)\n",
    "\n",
    "\n",
    "Place the decompressed file in the same path of the notebook. You should have the dataset in the current folder: ```./data/rt-polaritydata/```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "def load_data_and_labels(pos_file, neg_file):\n",
    "    \"\"\"\n",
    "    Loads MR polarity data from files, splits the data into words and generates labels.\n",
    "    Returns split sentences and labels.\n",
    "    \"\"\"\n",
    "    # Load data from files\n",
    "    positive_examples = list(open(pos_file, \"r\").readlines())\n",
    "    positive_examples = [s.strip() for s in positive_examples]\n",
    "    negative_examples = list(open(neg_file, \"r\").readlines())\n",
    "    negative_examples = [s.strip() for s in negative_examples]\n",
    "    # Split by words\n",
    "    x_text = positive_examples + negative_examples\n",
    "    x_text = [clean_str(sent) for sent in x_text]\n",
    "    # Generate labels\n",
    "    positive_labels = [1 for _ in positive_examples]\n",
    "    negative_labels = [0 for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    \n",
    "    data = pd.DataFrame(data={'text': x_text, 'label': y})\n",
    "    data = shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and make train and development partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: (10662, 2)\n",
      "\n",
      "Training set examples: 9000\n",
      "Development set examples: 1000\n"
     ]
    }
   ],
   "source": [
    "# data home\n",
    "sst_home = './data/rt-polaritydata/'\n",
    "dataset = load_data_and_labels(sst_home+'/rt-polarity.pos', sst_home+'rt-polarity.neg')\n",
    "\n",
    "print(\"dataset size:\", dataset.shape)\n",
    "\n",
    "training_set = dataset.head(9000)\n",
    "dev_set = dataset.tail(1000)\n",
    "\n",
    "# Obtain text and label vectors as lists \n",
    "train_texts = list(training_set.text)\n",
    "train_labels = list(training_set.label)\n",
    "\n",
    "dev_texts = list(dev_set.text)\n",
    "dev_labels = list(dev_set.label)\n",
    "\n",
    "print('')\n",
    "print('Training set examples: {}'.format(len(training_set)))\n",
    "\n",
    "print('Development set examples: {}'.format(len(dev_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2_examin_data'></a>\n",
    "### Examine the dataset\n",
    "We print some example of negative and positive cases, just to make an idea of what type of text we have.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>suffocated at conception by its munchausen by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6578</th>\n",
       "      <td>this loud and thoroughly obnoxious comedy abou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>ze movie starts out so funny , then she is not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>most new movies have a bright sheen some , lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>standard guns versus martial arts cliche with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>every bit as bogus as most disney live action ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8097</th>\n",
       "      <td>preposterous and tedious , sonny is spiked wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>fairly successful at faking some pretty cool s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10323</th>\n",
       "      <td>has not so much been written as assembled , fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>it 's drab it 's uninteresting it squanders ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "8337   suffocated at conception by its munchausen by ...      0\n",
       "6578   this loud and thoroughly obnoxious comedy abou...      0\n",
       "6452   ze movie starts out so funny , then she is not...      0\n",
       "7454   most new movies have a bright sheen some , lik...      0\n",
       "5857   standard guns versus martial arts cliche with ...      0\n",
       "7668   every bit as bogus as most disney live action ...      0\n",
       "8097   preposterous and tedious , sonny is spiked wit...      0\n",
       "8257   fairly successful at faking some pretty cool s...      0\n",
       "10323  has not so much been written as assembled , fr...      0\n",
       "6083   it 's drab it 's uninteresting it squanders ch...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a sample of negative text chunks\n",
    "training_set[training_set.label == 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>an enjoyably half wit remake of the venerable ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>it 's no lie big fat liar is a real charmer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>this riveting world war ii moral suspense stor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>grown up quibbles are beside the point here th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>despite its old hat set up and predictable plo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>runs on the pure adrenalin of pacino 's perfor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>does what a fine documentary does best it exte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>arliss howard 's ambitious , moving , and adve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>a warm but realistic meditation on friendship ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>do we really need a 77 minute film to tell us ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "948   an enjoyably half wit remake of the venerable ...      1\n",
       "2178        it 's no lie big fat liar is a real charmer      1\n",
       "1246  this riveting world war ii moral suspense stor...      1\n",
       "4820  grown up quibbles are beside the point here th...      1\n",
       "3234  despite its old hat set up and predictable plo...      1\n",
       "2140  runs on the pure adrenalin of pacino 's perfor...      1\n",
       "499   does what a fine documentary does best it exte...      1\n",
       "5312  arliss howard 's ambitious , moving , and adve...      1\n",
       "1154  a warm but realistic meditation on friendship ...      1\n",
       "624   do we really need a 77 minute film to tell us ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a sample of positive text chunks\n",
    "training_set[training_set.label == 1].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2_one_hot'></a>\n",
    "### One-hot encoding of the data\n",
    "\n",
    "One-hot encoding is the most basic way to convert a token into a vectort. Here, we'll turn the input vectors into (0,1)-vectors. The process consist of associating a unique integer-index with every word in the vocabulary.\n",
    "\n",
    ">>>>![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/vectorize_small.png)\n",
    "\n",
    "\n",
    "For example, if the tokenized vector contains a word that its dictionary index is 14, then in the processed vector, the 14th entry of the vector will be 1 and the rest will set to 0.\n",
    "\n",
    "Note that when using keras built-in tools for indexing, ```0``` is a reserved index that won't be assigned to any word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juletx/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/juletx/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text of the first examples: \n",
      "suffocated at conception by its munchausen by proxy mum punish the vehicle to adore the star\n",
      "\n",
      "Vector of the first example:\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "\n",
      "Binary representation of the output:\n",
      "0\n",
      "\n",
      "Shape of the training set (nb_examples, vector_size): (9000, 5000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# Create a tokenize that takes the nb_words most common words\n",
    "nb_words= 5000 # Changed from 1000\n",
    "tokenizer = text.Tokenizer(num_words=nb_words)\n",
    "\n",
    "# Build the word index (dictionary)\n",
    "tokenizer.fit_on_texts(train_texts) # Create word index using only training part\n",
    "\n",
    "# Vectorize texts into one-hot encoding representations\n",
    "x_train = tokenizer.texts_to_matrix(train_texts, mode='binary')\n",
    "x_dev = tokenizer.texts_to_matrix(dev_texts, mode='binary')\n",
    "          \n",
    "# Change variable names (not needed, actually)\n",
    "y_train = train_labels\n",
    "y_dev = dev_labels\n",
    "\n",
    "print('Text of the first examples: \\n{}\\n'.format(train_texts[0]))\n",
    "print('Vector of the first example:\\n{}\\n'.format(x_train[0]))\n",
    "print('Binary representation of the output:\\n{}\\n'.format(y_train[0]))\n",
    "\n",
    "print('Shape of the training set (nb_examples, vector_size): {}\\n'.format(x_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to obtain the lists of integers indices instead of the one-hot binary representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suffocated at conception by its munchausen by proxy mum punish the vehicle to adore the star\n",
      "[32, 4041, 25, 19, 25, 1, 1174, 5, 1, 239]\n"
     ]
    }
   ],
   "source": [
    "# Turns strings into list of integer indices\n",
    "print(train_texts[0])\n",
    "one_hot_results = tokenizer.texts_to_sequences(train_texts)\n",
    "print(one_hot_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2_word_index'></a>\n",
    "### Inspect created word-index\n",
    "It is good idea to check the word index created for the task at hand, as this is going to be input representation for the model. \n",
    "\n",
    "The code below prints out the most common words and the least common words in the training-set. Note that the our vocabulary is defined by the 1000 most common words in the training part, but the tokniezer extracted 17359 word-types.\n",
    "\n",
    "<a id='exercise1'></a>\n",
    "#### Exercise 1:\n",
    "\n",
    "> Try to answer the following questions:\n",
    ">\n",
    "> - What can be the problem of not removing __the most frequent__ words? They have no meaning\n",
    "> - What can be the problem of not removing __the least frequent__ words? Not to overfit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17352 unique tokens.\n",
      "\n",
      "Show the most frequent word index:\n",
      "   the (8581) --> 1\n",
      "   a (6227) --> 2\n",
      "   and (5232) --> 3\n",
      "   of (5210) --> 4\n",
      "   to (3660) --> 5\n",
      "   is (3004) --> 6\n",
      "   's (2990) --> 7\n",
      "   it (2948) --> 8\n",
      "   in (2288) --> 9\n",
      "   that (2233) --> 10\n",
      "\n",
      "Show the least frequent word index:\n",
      "   munchausen (1) --> 9134\n",
      "   proxy (1) --> 9135\n",
      "   mum (1) --> 9136\n",
      "   punish (1) --> 9137\n",
      "   adore (1) --> 9138\n",
      "   squabbling (1) --> 9139\n",
      "   venerable (1) --> 9140\n",
      "   ze (1) --> 9141\n",
      "   stillborn (1) --> 9142\n",
      "   quibbles (1) --> 9143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recorver the word index that was created with the tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens.\\n'.format(len(word_index)))\n",
    "word_count = tokenizer.word_counts\n",
    "print(\"Show the most frequent word index:\")\n",
    "for i, word in enumerate(sorted(word_count, key=word_count.get, reverse=True)):\n",
    "    print('   {} ({}) --> {}'.format(word, word_count[word], word_index[word]))\n",
    "    if i == 9: \n",
    "        print('')\n",
    "        break\n",
    "\n",
    "print(\"Show the least frequent word index:\")\n",
    "for i, word in enumerate(sorted(word_count, key=word_count.get, reverse=False)):\n",
    "    print('   {} ({}) --> {}'.format(word, word_count[word], word_index[word]))\n",
    "    if i == 9: \n",
    "        print('')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. Whatâ€™s going on inside a MLP? \n",
    "\n",
    "In this part, we provide you most of the code that in implement of a basic two layer (one hidden, and one output) multi-layer perceptron.  \n",
    "\n",
    "<a id='exercise2'></a>\n",
    "#### Exercise 2:\n",
    "> Modify the code to turn it into an MLP with one ReLU hidden layers of 50 dimensions. __Follow the instructions in the code__.\n",
    "\n",
    "> __Note__: Keep in mind that initializing weight matrices with zeros causes problems in deep neural networks trained by SGD. You should use tf.random_normal instead, with stddev=0.1.\n",
    "\n",
    "<a id='exercise3'></a>\n",
    "#### Exercise 3: \n",
    "> The model seems to learn something (loss values are slowly going down), but not much. Augment the size of vocabulary to 5000. Recall you need to preprocess the data again!\n",
    ">\n",
    "> > __I recommend to re-initialize kernel before you run again the model. I don't know why with re-initializing the model seems to get stuck in local minima when runing for the second time.__\n",
    ">\n",
    "> What is happening now? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(classifier, examples, labels):\n",
    "    correct = 0\n",
    "    hypotheses = classifier(examples)\n",
    "    labels = np.argmax(labels, axis=1)\n",
    "    for i, label in enumerate(labels):\n",
    "        hypothesis = hypotheses[i]\n",
    "        if hypothesis == label:\n",
    "            correct += 1        \n",
    "    return correct / float(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression_classifier:\n",
    "    def __init__(self, dim):\n",
    "        # Define the hyperparameters\n",
    "        self.learning_rate = 1.0  # Should be about right\n",
    "        self.training_epochs = 50  # How long to train for - chosen to fit within class time\n",
    "        self.display_epoch_freq = 1  # How often to test and print out statistics\n",
    "        self.dim = dim  # The number of features\n",
    "        self.batch_size = 128  # Somewhat arbitrary - can be tuned, but often tune for speed, not accuracy\n",
    "        \n",
    "        # TODO: Use this.\n",
    "        self.hidden_layer_size = 50\n",
    "        \n",
    "        # TODO: Overwrite this section\n",
    "        ### Start of model definition ###\n",
    "        \n",
    "        # Define the inputs\n",
    "        self.x = tf.placeholder(tf.float32, [None, dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 2])\n",
    "        \n",
    "        # Define (most of) the model's variable: input_size x hidden_layer_size \n",
    "        self.W0 = tf.Variable(tf.random_normal([self.dim, self.hidden_layer_size], stddev=0.1))\n",
    "        self.b0 = tf.Variable(tf.random_normal([self.hidden_layer_size], stddev=0.1))\n",
    "        \n",
    "        # TODO: Define variable, hidden_layer_size x number_of classes\n",
    "        self.W1 = tf.Variable(tf.random_normal([self.hidden_layer_size, 2], stddev=0.1))\n",
    "        self.b1 = tf.Variable(tf.random_normal([2], stddev=0.1))\n",
    "        \n",
    "        self.logits0 = tf.matmul(self.x, self.W0) + self.b0\n",
    "        self.h0 = tf.nn.relu(self.logits0)\n",
    "        \n",
    "        # TODO: Calculate the logits and prediction probabilities for each class. \n",
    "        self.logits1 = tf.matmul(self.h0, self.W1) + self.b1\n",
    "        self.pred = tf.nn.softmax(self.logits1)\n",
    "        \n",
    "        ### End of model definition ###\n",
    "        \n",
    "        # Define the cost function\n",
    "        self.cost = tf.reduce_mean(-tf.reduce_sum(self.y*tf.log(self.pred), reduction_indices=1))\n",
    "        \n",
    "        # Optionally you could add L2 regularization term\n",
    "        # correct?\n",
    "        regularizer = tf.nn.l2_loss(self.W1)\n",
    "        beta = 0.01\n",
    "        self.cost = tf.reduce_mean(self.cost + beta * regularizer)\n",
    "        \n",
    "        # This library call performs the main SGD update equation\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "        # Create an operation to fill zero values in for W0, W1, b0 and b1\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        \n",
    "        # Create a placeholder for the session that will be shared between training and evaluation\n",
    "        self.sess = None\n",
    "        \n",
    "    def train(self, training_set, dev_set):\n",
    "        def get_minibatch(dataset, start_index, end_index):\n",
    "            indices = range(start_index, end_index)\n",
    "            vectors = dataset[0][indices]\n",
    "            labels = dataset[1][indices]\n",
    "            return vectors, labels\n",
    "        \n",
    "        def shuffle_data(dataset):\n",
    "            combined = list(zip(dataset[0], dataset[1]))\n",
    "            random.shuffle(combined)\n",
    "            dataset[0][:], dataset[1][:] = zip(*combined)\n",
    "            \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(self.init)\n",
    "        print ('Training.')\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(self.training_epochs):\n",
    "            shuffle_data(training_set)\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(len(training_set[0]) / self.batch_size)\n",
    "            \n",
    "            # Loop over all batches in epoch\n",
    "            for i in range(total_batch):\n",
    "                # Assemble a minibatch of the next B examples\n",
    "                minibatch_vectors, minibatch_labels = get_minibatch(training_set, \n",
    "                                                                    self.batch_size * i, \n",
    "                                                                    self.batch_size * (i + 1))\n",
    "\n",
    "                # Run the optimizer to take a gradient step, and also fetch the value of the \n",
    "                # cost function for logging\n",
    "                _, c = self.sess.run([self.optimizer, self.cost], \n",
    "                                     feed_dict={self.x: minibatch_vectors,\n",
    "                                                self.y: minibatch_labels})\n",
    "                \n",
    "                # Compute average loss\n",
    "                avg_cost += c / total_batch\n",
    "                \n",
    "            # Display some statistics about the step\n",
    "            if (epoch+1) % self.display_epoch_freq == 0:\n",
    "                print (\"Epoch:\", (epoch+1), \"Cost:\", avg_cost, \\\n",
    "                    \"Dev acc:\", evaluate_classifier(self.classify, dev_set[0][0:500], dev_set[1][0:500]), \\\n",
    "                    \"Train acc:\", evaluate_classifier(self.classify, training_set[0][0:500], training_set[1][0:500]))\n",
    "    \n",
    "    def classify(self, examples):\n",
    "        # This classifies a list of examples\n",
    "        logits = self.sess.run(self.pred, feed_dict={self.x: examples})\n",
    "        return np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.\n",
      "Epoch: 1 Cost: 0.6749121555260252 Dev acc: 0.612 Train acc: 0.7\n",
      "Epoch: 2 Cost: 0.5626637186322894 Dev acc: 0.606 Train acc: 0.804\n",
      "Epoch: 3 Cost: 0.4298307891402925 Dev acc: 0.612 Train acc: 0.818\n",
      "Epoch: 4 Cost: 0.2526976879153933 Dev acc: 0.676 Train acc: 0.974\n",
      "Epoch: 5 Cost: 0.16443883819239477 Dev acc: 0.694 Train acc: 0.996\n",
      "Epoch: 6 Cost: 0.12122739904693187 Dev acc: 0.686 Train acc: 0.994\n",
      "Epoch: 7 Cost: 0.10176934312496864 Dev acc: 0.698 Train acc: 1.0\n",
      "Epoch: 8 Cost: 0.08631963665996281 Dev acc: 0.698 Train acc: 1.0\n",
      "Epoch: 9 Cost: 0.07797274834343361 Dev acc: 0.686 Train acc: 1.0\n",
      "Epoch: 10 Cost: 0.07092526491199216 Dev acc: 0.696 Train acc: 1.0\n",
      "Epoch: 11 Cost: 0.06576676810426374 Dev acc: 0.69 Train acc: 1.0\n",
      "Epoch: 12 Cost: 0.06103034280240536 Dev acc: 0.688 Train acc: 1.0\n",
      "Epoch: 13 Cost: 0.05735894276627472 Dev acc: 0.684 Train acc: 1.0\n",
      "Epoch: 14 Cost: 0.05403616433697088 Dev acc: 0.684 Train acc: 1.0\n",
      "Epoch: 15 Cost: 0.05075845840786182 Dev acc: 0.686 Train acc: 1.0\n",
      "Epoch: 16 Cost: 0.04826769631888185 Dev acc: 0.688 Train acc: 1.0\n",
      "Epoch: 17 Cost: 0.04576546549797056 Dev acc: 0.682 Train acc: 1.0\n",
      "Epoch: 18 Cost: 0.043790891021490086 Dev acc: 0.672 Train acc: 1.0\n",
      "Epoch: 19 Cost: 0.04219835954053063 Dev acc: 0.668 Train acc: 1.0\n",
      "Epoch: 20 Cost: 0.0400918848280396 Dev acc: 0.672 Train acc: 1.0\n",
      "Epoch: 21 Cost: 0.03821538362119879 Dev acc: 0.674 Train acc: 1.0\n",
      "Epoch: 22 Cost: 0.03674506992101668 Dev acc: 0.666 Train acc: 1.0\n",
      "Epoch: 23 Cost: 0.03532939313777855 Dev acc: 0.666 Train acc: 1.0\n",
      "Epoch: 24 Cost: 0.03418419265321323 Dev acc: 0.666 Train acc: 1.0\n",
      "Epoch: 25 Cost: 0.03309426281069006 Dev acc: 0.662 Train acc: 1.0\n",
      "Epoch: 26 Cost: 0.03193648127572878 Dev acc: 0.662 Train acc: 1.0\n",
      "Epoch: 27 Cost: 0.03098868578672409 Dev acc: 0.662 Train acc: 1.0\n",
      "Epoch: 28 Cost: 0.030137428481663963 Dev acc: 0.658 Train acc: 1.0\n",
      "Epoch: 29 Cost: 0.029168868064880376 Dev acc: 0.662 Train acc: 1.0\n",
      "Epoch: 30 Cost: 0.028251319830971105 Dev acc: 0.66 Train acc: 1.0\n",
      "Epoch: 31 Cost: 0.027244946333978854 Dev acc: 0.652 Train acc: 1.0\n",
      "Epoch: 32 Cost: 0.026490279260490614 Dev acc: 0.654 Train acc: 1.0\n",
      "Epoch: 33 Cost: 0.025967185092823846 Dev acc: 0.652 Train acc: 1.0\n",
      "Epoch: 34 Cost: 0.025461913352566104 Dev acc: 0.65 Train acc: 1.0\n",
      "Epoch: 35 Cost: 0.024992337530212738 Dev acc: 0.65 Train acc: 1.0\n",
      "Epoch: 36 Cost: 0.02436516423310552 Dev acc: 0.652 Train acc: 1.0\n",
      "Epoch: 37 Cost: 0.02368866010968175 Dev acc: 0.65 Train acc: 1.0\n",
      "Epoch: 38 Cost: 0.023079953236239296 Dev acc: 0.65 Train acc: 1.0\n",
      "Epoch: 39 Cost: 0.02271524343107428 Dev acc: 0.652 Train acc: 1.0\n",
      "Epoch: 40 Cost: 0.022192195164305827 Dev acc: 0.652 Train acc: 1.0\n",
      "Epoch: 41 Cost: 0.021568750457039904 Dev acc: 0.654 Train acc: 1.0\n",
      "Epoch: 42 Cost: 0.021054498744862423 Dev acc: 0.656 Train acc: 1.0\n",
      "Epoch: 43 Cost: 0.020720055273600983 Dev acc: 0.662 Train acc: 1.0\n",
      "Epoch: 44 Cost: 0.020239091824207984 Dev acc: 0.656 Train acc: 1.0\n",
      "Epoch: 45 Cost: 0.020025692427796976 Dev acc: 0.656 Train acc: 1.0\n",
      "Epoch: 46 Cost: 0.01969420824732099 Dev acc: 0.654 Train acc: 1.0\n",
      "Epoch: 47 Cost: 0.019302488145019326 Dev acc: 0.654 Train acc: 1.0\n",
      "Epoch: 48 Cost: 0.01896928761686598 Dev acc: 0.654 Train acc: 1.0\n",
      "Epoch: 49 Cost: 0.01862611728055136 Dev acc: 0.654 Train acc: 1.0\n",
      "Epoch: 50 Cost: 0.018333779541509488 Dev acc: 0.652 Train acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Converts the labels to a one-hot representation\n",
    "y_train_onehot = np.array(to_categorical(y_train))\n",
    "y_dev_onehot = np.array(to_categorical(y_dev))\n",
    "\n",
    "classifier = logistic_regression_classifier(nb_words)\n",
    "classifier.train([x_train, y_train_onehot], [x_dev, y_dev_onehot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## 4. MLP in Keras\n",
    "\n",
    "When we build a neural network we usually take into account the following points:\n",
    "- The __layers__, and how they are combined (that is, the structure and parameters of the model)\n",
    "- The __input__ and the __labeled output__ data that the model needs to map.\n",
    "- __Loss function__ that signals how well the model is doing.\n",
    "- The __optimizier__ which defines the learning procedure.\n",
    "\n",
    "Keras provide a simple framework for combining layers. There are available two types of classes for building the model: The _Sequential_ Class and the _functional_ API. The later is dedicated to DAGs structures, which let you to build arbitrary models. The former is for linear stacks of layers, which is the most common and simplest type of archicture. \n",
    "\n",
    "We built a simple MLP model in TensorFlow which one the most simple neural network model, but I took some lines of codes. On the contrary, the MLP model can be implemented in Keras stacking ```Dense``` layers with some kind of non-linearity. \n",
    "\n",
    "Regarding input data, we will use the __one-hot encoding__ (see above). We'll set ```(binary) cross-entropy``` as a __loss function__ and ```sgd``` (_Stochastic Gradient Descent_) as the __optimizer__ to build an equivalent model in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/juletx/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                250050    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 250,101\n",
      "Trainable params: 250,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# make reproducible code\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "seed(1)\n",
    "\n",
    "input_size = x_train[0].shape[0] ## vector length equals to vocabulary size.\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=50, activation='relu', input_shape=(input_size,)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  \n",
    "# Note that we do not need to indicate the input shape for the sucessives layes\n",
    "\n",
    "# Compile the model using a loss function and an optimizer.\n",
    "sgd = SGD(lr=1.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/juletx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/juletx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/juletx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=25, batch_size=128, validation_data=(x_dev, y_dev), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "                    \n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc.')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "                    \n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on dev: 0.5360000133514404 (epoch 19)\n"
     ]
    }
   ],
   "source": [
    "best_idx = np.argmax(history.history['val_accuracy'])\n",
    "print(\"Best accuracy on dev: {} (epoch {})\".format(history.history['val_accuracy'][best_idx], best_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reproducible models**\n",
    "Run the code below if you want to train your model from scratch. \n",
    "\n",
    "`Clear_session` will destroys the current TF graph and creates a new one. Useful to avoid clutter from old models / layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4_model_optimization'></a>\n",
    "### 4.1 Model Optimization\n",
    "\n",
    "How much can we improve the current classifier? We can follow multiple strategies to improve the performance of our model: \n",
    "\n",
    "- **Increase training size**: Usually this is the most effective way to improve the resuls, but it is the most costly at the same time. In our case we are using the whole dataset, so we can't exploit this estrategy (you can simulate by using smaller set of training as baseline).\n",
    "\n",
    "- **Increase vocabulary**: We are not using the whole vocabulary of the training set. Vocabulary pruning can be useful to avoid overfiting, but can affect generalization properties as well.\n",
    "\n",
    "- **The use of correct neural archictecture**: We can increase the expresivity of the model by adding more parameters in different forms: 1) increasing number of hidden layers, 2) increasing the size of layers, 3) combining both. \n",
    "\n",
    "- **The use of correct optimization strategy**: We can try more effective optimizers than SGD. For example, Adam optimizer is one of the most popular in NLP. In many cases correct learning rate value makes a difference. So exploring different learning rate values can be interesting choice to improve results.\n",
    "\n",
    "- **Number of epochs**: How long we traing is something we need too control as training to long can derive to overfit the model. On the contrary, if we train for a short time the model will hardly learn anything. There are different ways to select number of training epochs, but a common one is to inspect learning curves and select the point that has lower loss in development. \n",
    "\n",
    "- **Regularization weight, dropout, batch size, etc.**: Deep learning is full of hyperparameters and small *tricks* that are important to know. Each model in a particular task has its own optimum values which we don't know in advance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise4'></a>\n",
    "#### Exercise 4: \n",
    " * Explore what happens when we use the whole vocabulary instead to the most 1000 frequent words.\n",
    " * It looks like learning is quite unstable as the accuracy on development fluctuates quite significantly. Select a smaller learning rate (e.g. 0.1 or even smaller). You'll probably need to train longer.   \n",
    " * Now, explore what happens when we increase the model (e.g. 300 > 50 > 1). You might need to adjust the learning rate and the number of epochs. \n",
    " * Now, explore with a different optimizer (e.g Adam).\n",
    " \n",
    " What's your best accuracy and model's detail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 17353)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# In order to use the whole vocabulary you need to preprocess the data again.\n",
    "# You can use the code in section 2.3\n",
    "\n",
    "# TODO: \n",
    "# Create a tokenizer object with 'num_words=None' as argument.\n",
    "tokenizer = text.Tokenizer(num_words=None)\n",
    "\n",
    "# TODO:\n",
    "# Build the word index (dictionary)\n",
    "tokenizer.fit_on_texts(train_texts) # Create word index using only training part\n",
    "\n",
    "# TODO:\n",
    "# Vectorize texts into one-hot encoding representations\n",
    "x_train = tokenizer.texts_to_matrix(train_texts, mode='binary')\n",
    "x_dev = tokenizer.texts_to_matrix(dev_texts, mode='binary')\n",
    "\n",
    "# Change variable names (not needed, actually)\n",
    "y_train = train_labels\n",
    "y_dev = dev_labels\n",
    "\n",
    "nb_words = x_train.shape[1]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New input size: 17353\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "input_size = x_train[0].shape[0] ## vector length equals to vocabulary size.\n",
    "print(\"New input size: {}\".format(input_size))\n",
    "\n",
    "# TODO:\n",
    "# Define the model\n",
    "model_av = Sequential()\n",
    "model_av.add(Dense(units=300, activation='relu', input_shape=(input_size,)))\n",
    "model_av.add(Dense(units=50, activation='relu'))\n",
    "model_av.add(Dense(units=1, activation='sigmoid'))  \n",
    "    \n",
    "# TODO: \n",
    "# Define the optimizer (SGD, Adam, etc.)\n",
    "sgd = SGD(lr=0.1)\n",
    "adam = Adam(lr=0.1)\n",
    "\n",
    "# TODO:\n",
    "# Compile the model using a loss function and an optimizer.\n",
    "model_av.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# TODO: \n",
    "# Fit the model with the appropiate number of epochs and batch size\n",
    "history_av = model_av.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_dev, y_dev), verbose=0)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_av.history['accuracy'])\n",
    "plt.plot(history_av.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc.')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on dev: 0.7699999809265137 (epoch 3)\n"
     ]
    }
   ],
   "source": [
    "best_idx = np.argmax(history_av.history['val_accuracy'])\n",
    "print(\"Best accuracy on dev: {} (epoch {})\".format(history_av.history['val_accuracy'][best_idx], best_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## 5. Other models for text: LSTM\n",
    "\n",
    "When working with text it is typical to model the input as it would be time dependent series. Due to compositional nature of language, we could encode the semantics of the context conditioning on previous seen words, and **Deep Recurrent Neural Networks** are suitable to model these ideas. \n",
    "\n",
    "In this section, we will use Keras to implement a more advanced __Long Short Term Memory__ (LSTM) based sentiment classifier. \n",
    "\n",
    "----\n",
    "\n",
    "Remenber from the theory that Recurrent Neural Networks apply over and over the same function (the recursive cell) to every token in the sequence. In a simplified version the next token is combined with the output of the previous _state_ (contains the information of what has been seen so far) into the recursive function, so that the whole sequence is represented in a single vector. \n",
    "\n",
    "Figure below shows an unrolled LSTM archicture, in which input text sequence, once tokenized and obtained the word index, is represented by word embeddings. Emebdding lookup layer takes a list of word indexes and returns a list word embeddings (low-dimensional dense vectors that represent words). These word embeddings are what actually fed to sentence encoder. Finally, the last output of the LSTM is fed to a fully connected Dense layer. As we'll learn, this is fairly easy to code with Keras.\n",
    "\n",
    "\n",
    "![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/LSTM_sentiment.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5_padding'></a>\n",
    "### Padding sequences\n",
    "When process data to feed a recurrent archicture, we need to do it differently compared to what we have seen so far. Unrolling each sequence one by one would take forever, as we would lose the capability for parallelization. That's why we need to pad the input sentences. That is, as learning is typically done by mini-batching the training data, it requires having same sequence length for all the input examples in the mini-batch so we can run the operation in parallel over the whole batch.\n",
    "\n",
    "In order to do mini-batch we need to do the following:\n",
    "- Choose a single unrolling constant N (e.g. max sequence length)\n",
    "- Pad first words with zeros (shifting right)\n",
    "\n",
    "\n",
    "There are more sophisticated alternivatives like shuffling examples by sentence length (set N to max. length in mini-batch), but for our purposes that would be enough. \n",
    "\n",
    "In the following chunk of code, we will use Keras built-in functions for padding sequence. Note that tokenization and word-indexing is already done in <a href='#section2_one_hot'>Section 2.3 (One-hot encoding of the data)</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set (nb_examples, vector_size): (9000, 40)\n",
      "Shape of the validation set (nb_examples, vector_size): (1000, 40)\n",
      "\n",
      "TEXT: suffocated at conception by its munchausen by proxy mum punish the vehicle to adore the star\n",
      "PADDED: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0 6416   32 4041   25\n",
      "   19 9134   25 9135 9136 9137    1 1174    5 9138    1  239]\n",
      "\n",
      "TEXT: this loud and thoroughly obnoxious comedy about a pair of squabbling working class spouses is a deeply unpleasant experience\n",
      "PADDED: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0   16  686    3  715 2038   58   30\n",
      "    2 2267    4 9139  687  526 6417    6    2  492 1334  312]\n"
     ]
    }
   ],
   "source": [
    "# Recall from previous code sections:\n",
    "# - training text examples: train_texts\n",
    "# - training labels: train_labels\n",
    "#\n",
    "# - development text examples: dev_texts\n",
    "# - development labels: dev_labels\n",
    "\n",
    "from keras import preprocessing\n",
    "\n",
    "# Define maximum sequence length\n",
    "max_seq = 40 \n",
    "\n",
    "# Get data as a lists of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "dev_sequences = tokenizer.texts_to_sequences(dev_texts)\n",
    "nb_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Padding data: Turn the lists of integers into a 2D integer tensor of shape `(samples, max_seq)`\n",
    "x_train = preprocessing.sequence.pad_sequences(train_sequences, maxlen=max_seq)\n",
    "x_dev = preprocessing.sequence.pad_sequences(dev_sequences, maxlen=max_seq)\n",
    "\n",
    "y_train = train_labels\n",
    "y_dev = dev_labels\n",
    "\n",
    "print('Shape of the training set (nb_examples, vector_size): {}'.format(x_train.shape))\n",
    "print('Shape of the validation set (nb_examples, vector_size): {}'.format(x_dev.shape))\n",
    "\n",
    "# Print some examples\n",
    "print()\n",
    "print('TEXT: {}\\nPADDED: {}'.format(train_texts[0], x_train[0]))\n",
    "print()\n",
    "print('TEXT: {}\\nPADDED: {}'.format(train_texts[1], x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise5'></a>\n",
    "#### Exercise 5\n",
    ">Differences of the embedding representation with the one-hot encoding.\n",
    ">- Do we keep now the temporal order of words?\n",
    ">- What is one of the goal of the embedding table? Would be possile to apply LSTMs to text with the one-hot encoding representation?\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section5_lstm></a>\n",
    "### Build a LSTM model in few lines\n",
    "In this section we will build our first LSTM-based classifier in Keras. Note that the LSTM layer, like the rest of layers in Keras, takes inputs of shape ```[batch_size, sequence_length, input_features]```. This is the reason of why we perform padding when preprocessed the data in the previous section.\n",
    "\n",
    "Note that after the padding our data still is 2D tensor of shape ```[batch_size, sequence_length]```. Transformation from 2D to 3D is done with```Embedding``` layer in Keras, which takes the 2D tensor (```[batch_size, sequence_length]```). ```sequence_length``` is an entry of a list of word indexes, where all the entries in the bacth have the same length. (That's why we padded with zeros the shorter sequences).\n",
    "\n",
    "```Embedding``` layer return a tensor of shape ```[batch_size, sequence_length, embedding_size]```. This can be understood like adding the corresponding embedded vector to each word in the sequence. The layer can be initialized at radom and learn with backpropagation, or use precomputed embedding vector like _Word2vec_ or _Glove_.\n",
    "\n",
    "Once our data is represented with 3D tensors we can use directly the ```LSTM``` layer. For this task we will combine three Keras layers in this specific order: \n",
    "\n",
    "- ```Embedding``` layer: it will transfor the data from 2D to 3D by adding associated embeddings to words in the sequences. In the constructor we need to specify two arguments: \n",
    "   - input_dim: int > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "   - output_dim: int >= 0. Dimension of the dense embedding.\n",
    "   \n",
    "- ```LSTM``` layer: It will encode the input sequnces and return output tensor. For the LSTM we need to specify the number of units of the LSTM:\n",
    "   - units: Positive integer, dimensionality of the output space.\n",
    "   \n",
    "- ```Dense```: It will take the output of the LSTM as input and perform the classification. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise6'></a>\n",
    "#### Exercise 6: \n",
    "> Complete the code to turn it into a LSTM. You just need to add the LSTM layer in Keras, and another layer for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 17353\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 128)         2221184   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,352,897\n",
      "Trainable params: 2,352,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "# nb_words defined above \n",
    "print('Vocabulary size: {}'.format(nb_words))\n",
    "embedding_size = 128\n",
    "\n",
    "# TODO: Use this\n",
    "lstm_hidden_size = 128 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1. Define and add Embedding layer to the model. \n",
    "#    Note we are using mask_zero=True as we want to ignore the '0' words in the padding\n",
    "model.add(Embedding(nb_words, embedding_size, mask_zero=True))\n",
    "# After the Embedding layer, \n",
    "# our activations have shape `(batch_size, max_seq, embedding_size)`.\n",
    "\n",
    "# TODO: \n",
    "# 2. Define and add LSTM layer to the model.\n",
    "model.add(LSTM(units=lstm_hidden_size, activation='relu'))\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# 3. Define and add Dense layer to the model\n",
    "model.add(Dense(units=1, activation='sigmoid'))  \n",
    "\n",
    "\n",
    "# Define optimizer:\n",
    "opt=Adam(lr=0.001)\n",
    "# Compile the model using a loss function and an optimizer.\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "9000/9000 [==============================] - 13s 1ms/step - loss: 0.6543 - accuracy: 0.6121 - val_loss: 0.5448 - val_accuracy: 0.7550\n",
      "Epoch 2/10\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.3736 - accuracy: 0.8480 - val_loss: 0.4879 - val_accuracy: 0.7580\n",
      "Epoch 3/10\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.1788 - accuracy: 0.9356 - val_loss: 0.5940 - val_accuracy: 0.7820\n",
      "Epoch 4/10\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0961 - accuracy: 0.9664 - val_loss: 0.8507 - val_accuracy: 0.7580\n",
      "Epoch 5/10\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.0504 - accuracy: 0.9827 - val_loss: 0.9336 - val_accuracy: 0.7650\n",
      "Epoch 6/10\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.0884 - accuracy: 0.9763 - val_loss: 1.5969 - val_accuracy: 0.7580\n",
      "Epoch 7/10\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.0443 - accuracy: 0.9899 - val_loss: 0.9754 - val_accuracy: 0.7560\n",
      "Epoch 8/10\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 1.1364 - val_accuracy: 0.7590\n",
      "Epoch 9/10\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.0256 - accuracy: 0.9979 - val_loss: 1.0107 - val_accuracy: 0.7510\n",
      "Epoch 10/10\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.0161 - accuracy: 0.9973 - val_loss: 1.1524 - val_accuracy: 0.7460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_dev, y_dev), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on dev: 0.7820000052452087 (epoch 2)\n"
     ]
    }
   ],
   "source": [
    "best_idx = np.argmax(history.history['val_accuracy'])\n",
    "print(\"Best accuracy on dev: {} (epoch {})\".format(history.history['val_accuracy'][best_idx], best_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5_cnn'></a>\n",
    "### 1D CNNs for texts (optional)\n",
    "\n",
    "The model architecture for texts are much like a 2D CNN that are tipically used in computer vision. Instead of having two dimension for applying convolutional filters, in this case, due to the sequential nature of the data, convolutions are applied along one axis (See image below). \n",
    "\n",
    "CNN based archictures for sentence classification have tipically the following layers:\n",
    "\n",
    "- __Convolutional layer__: It uses convolutions that extracts local 1D patches (subsequences) from the input sentences. Recall that word indeces are first transformed to embedding space. This type of convolutions can recognize local patterns such as bigrams and trigrams.  As explained in class, convolution layers change the shape of the input sequence. Depending on the type of padding and stride the length of the output would be longer, same size, or shorter. The depending on the number of filters used the output depth would change as well.\n",
    "\n",
    "  If ```padding = 'same'```, then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "  ```output_length = ceil(input_length / stride)```\n",
    "\n",
    "  If ```padding = 'valid'```, then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "  ```output_length = ceil(input_length - kernel_size + 1) / stride)```\n",
    "\n",
    "\n",
    "- __Max-pooling layer__: The main objective is to reduce drastically the output size of the convolution layers. 1D pooling operation is the same as the 2D. It takes 1D subsequences from convolutional output as input and return the maximum value. Similarly to convolutional layer, depending on the ```pool_size```, ```stride``` and ```padding``` we'd obtain different reduction of the input size.\n",
    "\n",
    "- __Fully connected layer__: We can flatten the output of the max-pooling layer and feed to fully-connected layer to perform _positive_ vs _negative_ classification.\n",
    "\n",
    "\n",
    ">>>![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/CNN_for_texts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise7'></a>\n",
    "#### Exercise 7 (optional)\n",
    "Following the idea explained in the introduction of the notebook, you will stack two layers of ```convolution+max-pooling```. Note that the last layer of max-pooling is ```GlobalMaxPooling1D```, which returns a flat vector that can be directly feed in the ```Dense``` layer for doing classification.\n",
    "\n",
    "__Hint__: You need to combine the following keras layers:\n",
    "- ```Embedding```\n",
    "- ```Conv1D```\n",
    "- ```MaxPoolling1D```\n",
    "- ```GlobalMaxPooling1D```\n",
    "- ```Dense```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 40, 128)           2221184   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 31, 32)            40992     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 6, 32)             10272     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,272,481\n",
      "Trainable params: 2,272,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "max_words = nb_words ## defined above\n",
    "max_seq = 40 ## defined above\n",
    "embedding_size = 128 \n",
    "output_filters = 32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: Define the model. conv1d+max_pooling + convd1+globalmaxpooling + dense\n",
    "#       Activations. Typically RELU works OK in this type of tasks.\n",
    "model.add(Embedding(nb_words, embedding_size, input_length=max_seq))\n",
    "\n",
    "model.add(Conv1D(filters=output_filters, kernel_size=10, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(filters=output_filters, kernel_size=10, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 4s 444us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.4990\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 3s 327us/step - loss: 0.6903 - acc: 0.5611 - val_loss: 0.6928 - val_acc: 0.5100\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 3s 336us/step - loss: 0.6869 - acc: 0.6201 - val_loss: 0.6922 - val_acc: 0.5140\n",
      "Epoch 4/20\n",
      "9000/9000 [==============================] - 3s 310us/step - loss: 0.6827 - acc: 0.6743 - val_loss: 0.6902 - val_acc: 0.5310\n",
      "Epoch 5/20\n",
      "9000/9000 [==============================] - 3s 321us/step - loss: 0.6763 - acc: 0.7068 - val_loss: 0.6861 - val_acc: 0.5730\n",
      "Epoch 6/20\n",
      "9000/9000 [==============================] - 3s 319us/step - loss: 0.6660 - acc: 0.7214 - val_loss: 0.6769 - val_acc: 0.6180\n",
      "Epoch 7/20\n",
      "9000/9000 [==============================] - 3s 303us/step - loss: 0.6475 - acc: 0.7353 - val_loss: 0.6601 - val_acc: 0.6420\n",
      "Epoch 8/20\n",
      "9000/9000 [==============================] - 3s 305us/step - loss: 0.6188 - acc: 0.7420 - val_loss: 0.6387 - val_acc: 0.6520\n",
      "Epoch 9/20\n",
      "9000/9000 [==============================] - 3s 302us/step - loss: 0.5784 - acc: 0.7714 - val_loss: 0.6034 - val_acc: 0.6930\n",
      "Epoch 10/20\n",
      "9000/9000 [==============================] - 3s 319us/step - loss: 0.5288 - acc: 0.7954 - val_loss: 0.5715 - val_acc: 0.7160\n",
      "Epoch 11/20\n",
      "9000/9000 [==============================] - 3s 349us/step - loss: 0.4753 - acc: 0.8200 - val_loss: 0.5452 - val_acc: 0.7280\n",
      "Epoch 12/20\n",
      "9000/9000 [==============================] - 3s 369us/step - loss: 0.4233 - acc: 0.8421 - val_loss: 0.5148 - val_acc: 0.7410\n",
      "Epoch 13/20\n",
      "9000/9000 [==============================] - 3s 386us/step - loss: 0.3766 - acc: 0.8558 - val_loss: 0.4992 - val_acc: 0.7480\n",
      "Epoch 14/20\n",
      "9000/9000 [==============================] - 3s 350us/step - loss: 0.3360 - acc: 0.8757 - val_loss: 0.5049 - val_acc: 0.7610\n",
      "Epoch 15/20\n",
      "9000/9000 [==============================] - 3s 388us/step - loss: 0.3026 - acc: 0.8860 - val_loss: 0.4954 - val_acc: 0.7690\n",
      "Epoch 16/20\n",
      "9000/9000 [==============================] - 3s 382us/step - loss: 0.2735 - acc: 0.9000 - val_loss: 0.4924 - val_acc: 0.7660\n",
      "Epoch 17/20\n",
      "9000/9000 [==============================] - 3s 341us/step - loss: 0.2486 - acc: 0.9099 - val_loss: 0.5151 - val_acc: 0.7690\n",
      "Epoch 18/20\n",
      "9000/9000 [==============================] - 3s 338us/step - loss: 0.2274 - acc: 0.9170 - val_loss: 0.5222 - val_acc: 0.7680\n",
      "Epoch 19/20\n",
      "9000/9000 [==============================] - 3s 355us/step - loss: 0.2091 - acc: 0.9252 - val_loss: 0.5362 - val_acc: 0.7670\n",
      "Epoch 20/20\n",
      "9000/9000 [==============================] - 3s 340us/step - loss: 0.1918 - acc: 0.9313 - val_loss: 0.5581 - val_acc: 0.7660\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_dev, y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Word Embeddings\n",
    "\n",
    "In this part of the lab session we will learn what kind of thing can be don with the word embeddings. \n",
    "\n",
    "We will focus in three task:\n",
    "- __Task 1__: Word similarity and relatedness\n",
    "- __Task 2__: Score semantically the words\n",
    "- __Task 3__: Do analogies, like _Man is to King like Woman is to Queen_\n",
    "\n",
    "But as always, We will start setting up the environment and loading the data . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## Set up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define some helper functions for printing results and reading embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_header(title):\n",
    "    print('â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”')\n",
    "    print('â”‚{0:^63}â”‚'.format(title))\n",
    "    print('â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤')\n",
    "\n",
    "def print_footer():\n",
    "    print('â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜')\n",
    "\n",
    "def print_oov(oov):\n",
    "    if len(oov) > 0:\n",
    "        print('OOV: {0}'.format(', '.join(oov)))\n",
    "\n",
    "def print_row(index, last, trg_words, knn, sim):\n",
    "    if last >= index or index < 0:\n",
    "        return last\n",
    "    if last < index - 1:\n",
    "        print('â”‚  {0:>5}  â”‚  {0:^25}  â”‚  {0:>5}   â”‚  {0:^7} â”‚'.format('â‹®'))\n",
    "    word = trg_words[knn[index]]\n",
    "    word = ('{0:^25}').format(word)\n",
    "    print('â”‚  {0:>6}  â”‚  {1}  â”‚  {2:>6}  â”‚  {3:7.4f}  â”‚'.format(index + 1, word, knn[index], sim[knn[index]]))\n",
    "    return index\n",
    "\n",
    "def read(file, threshold=0, dim=50, vocabulary=None):\n",
    "    count = 400000 if threshold <= 0 else min(threshold, 400000)\n",
    "    words = []\n",
    "    matrix = np.empty((count, dim)) if vocabulary is None else []\n",
    "    for i in range(count):\n",
    "        word, vec = file.readline().split(' ', 1)\n",
    "        if vocabulary is None:\n",
    "            words.append(word)\n",
    "            matrix[i] = np.fromstring(vec, sep=' ')\n",
    "        elif word in vocabulary:\n",
    "            words.append(word)\n",
    "            matrix.append(np.fromstring(vec, sep=' '))\n",
    "    return (words, matrix) if vocabulary is None else (words, np.array(matrix))\n",
    "\n",
    "def length_normalize(matrix):\n",
    "    norms = np.sqrt(np.sum(matrix**2, axis=1))\n",
    "    norms[norms == 0] = 1\n",
    "    return matrix / norms[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6_load'></a>\n",
    "### Load data\n",
    "\n",
    "First let's load a set of 50D word vectors from GloVe. Original files can be downloaded at this [url](http://nlp.stanford.edu/data/glove.6B.zip). The zip file includes embeddings of different dimensionality (50d, 100d, 200d, 300d) for a vocabulary of 400000 words.\n",
    "\n",
    "We already provide you the required file, which is specifified in \n",
    "`glove_home`. \n",
    "\n",
    "Variables like `matrix` and `word2ind` are used below in the notebook so you need first load data in order to make everything work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input embeddings\n",
    "glove_home = 'data/embeddings/glove.6B.50d.txt'\n",
    "embsfile = open(glove_home, encoding='utf-8', errors='surrogateescape')\n",
    "words, matrix = read(embsfile)\n",
    "\n",
    "# Length normalize embeddings so their dot product effectively computes the cosine similarity\n",
    "matrix = length_normalize(matrix)\n",
    "\n",
    "# Build word to index map\n",
    "word2ind = {word: i for i, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>\n",
    "## Task 1: Semantically similar/related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(word, k=10):\n",
    "    try:\n",
    "        i = word2ind[word]\n",
    "        sim = matrix[i].dot(matrix.T)\n",
    "        knn = np.argsort(-sim)\n",
    "    except KeyError:\n",
    "        print_header('{0} (OOV)'.format(word))\n",
    "        print_footer()\n",
    "        print()\n",
    "        return\n",
    "    print_header('{0} ({1})'.format(word, i + 1))\n",
    "    last = -1\n",
    "    for j in range(len(knn)):\n",
    "        word = words[knn[j]]\n",
    "        if j < k:\n",
    "            last = print_row(j, last=last, trg_words=words, knn=knn, sim=sim)\n",
    "    last = print_row(len(knn)-1, last=last, trg_words=words, knn=knn, sim=sim)\n",
    "    print_footer()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`knn` function retrieve the _k_ most similar/related words of the target word according to the given embedding space. The output looks like the following:\n",
    "\n",
    "   - fist column for nearest neighbour index\n",
    "   - second column for nearest neighbour word\n",
    "   - third column for index of word in frequency ranking (1 is most frequent)\n",
    "   - last column for cosine (1 for perfect similarity)\n",
    "\n",
    "<a id='exercise8'></a>\n",
    "#### Exercise 8\n",
    ">Check the results for the words below. List which words you think are working well, and which ones it is failing. You can use the example in the slide  as reference.\n",
    ">\n",
    ">- france, jesus, xbox, reddish, scratched, megabits \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn('jesus',k=30)\n",
    "knn('france', k=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section8'></a>\n",
    "## Task2: Semantic Orientation\n",
    "The __semantic orientation__ method of [Turney and Littman 2003](http://doi.acm.org/10.1145/944012.944013) is a method for automatically scoring words along some single semantic dimension like sentiment. It works from a pair of small seed sets of words that represent two opposing points on that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_pos = ['good', 'great', 'awesome', 'like', 'love']\n",
    "seed_neg = ['bad', 'awful', 'terrible', 'hate', 'dislike']\n",
    "\n",
    "def determine_coefficient(candidate_word, seed_pos, seed_neg):\n",
    "    pos_ind = np.array([word2ind[word] for word in seed_pos])\n",
    "    pos_mat = matrix[pos_ind]\n",
    "\n",
    "    neg_ind = np.array([word2ind[word] for word in seed_neg])\n",
    "    neg_mat = matrix[neg_ind]\n",
    "\n",
    "    i = word2ind[candidate_word]\n",
    "\n",
    "    pos_sim = np.sum(matrix[i].dot(pos_mat.T))\n",
    "    neg_sim = np.sum(matrix[i].dot(neg_mat.T))\n",
    "\n",
    "    return pos_sim - neg_sim\n",
    "\n",
    "print(determine_coefficient('abhorrent', seed_pos, seed_neg))\n",
    "print(determine_coefficient('vacations', seed_pos, seed_neg))\n",
    "print(determine_coefficient('hunger', seed_pos, seed_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sort our vocabulary by its score along the axis. For now, we're only scoring frequent words, since this process can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "scored_words = [(word, determine_coefficient(word, seed_pos, seed_neg)) for word in words[1:5000]]\n",
    "sorted_words = sorted(scored_words, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "pp.pprint(sorted_words[:10])\n",
    "print()\n",
    "pp.pprint(sorted_words[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise9'></a>\n",
    "#### Exercise 9\n",
    "\n",
    "> Spend a few minutes exploring possible seed sets for semantic dimensions other than sentiment (e.g. \"animals\" vs \"tools\"). \n",
    ">- Define your semantic orientation with the two sets of seeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section9'></a>\n",
    "## Task 3: Analogy\n",
    "Next, let's try to build a similar function for determining which words are likely to be good completions for an analogy. Our inputs will be a pair and a singleton word that together represent an analogy problem.\n",
    "\n",
    "- Analogy pair:  good $\\rightarrow$ best,  man $\\rightarrow$ king\n",
    "- Analogy problem: bad $\\rightarrow$ ??,  woman $\\rightarrow$ ??\n",
    "\n",
    "\n",
    "Remenber from slides:\n",
    "\n",
    "- Task: _a is to b as c is to?_\n",
    "    + $a-b \\approx c-d$\n",
    "    + $c-a+b \\approx d$\n",
    "    + $argmax_{d\\in V} (cos(d , câˆ’a+b))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(pront_pair, pront_seed, k=10):\n",
    "    # The function make use of embedding matrix and word indices.\n",
    "    # Recall to load data and inialize matrix and word2ind variables.\n",
    "    try:\n",
    "        i = word2ind[pront_pair[0]]\n",
    "        w1v = matrix[i]\n",
    "    except KeyError:\n",
    "        print_header('{0} (OOV)'.format(pront_pair[0]))\n",
    "        print_footer()\n",
    "        print()\n",
    "        return\n",
    "    try:\n",
    "        i = word2ind[pront_pair[1]]\n",
    "        w2v = matrix[i]\n",
    "    except KeyError:\n",
    "        print_header('{0} (OOV)'.format(pront_pair[1]))\n",
    "        print_footer()\n",
    "        print()\n",
    "        return\n",
    "    try:\n",
    "        i = word2ind[pront_seed]\n",
    "        w3v = matrix[i]\n",
    "    except KeyError:\n",
    "        print_header('{0} (OOV)'.format(pront_seed))\n",
    "        print_footer()\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    ########### YOUR SOLUTION HERE\n",
    "    \n",
    "\n",
    "    ###########\n",
    "\n",
    "    print_header('{0} - {1} + {2}'.format(pront_pair[0], pront_pair[1], pront_seed))\n",
    "    last = -1\n",
    "    for j in range(len(knn)):\n",
    "        word = words[knn[j]]\n",
    "        if j < k:\n",
    "            last = print_row(j, last=last, trg_words=words, knn=knn, sim=sim)\n",
    "    last = print_row(len(knn)-1, last=last, trg_words=words, knn=knn, sim=sim)\n",
    "    print_footer()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercise10'></a>\n",
    "#### Exercise 10\n",
    ">-  The embeddings space can be used to do analogies. Please examine the formula in the of slides, and apply it to the three embeddings in the function below `analogy`. If you programmed it correctly, the following analogy should work:\n",
    ">    + `man:king; woman:?` (Note that, in the result list, words in the query need to be ignored)\n",
    ">    \n",
    ">\n",
    ">- Check 10 of the analogie below and see the position of the correct answer (discounting the words in the query).\n",
    "\n",
    ">>> ![](http://ixa2.si.ehu.es/~jibloleo/uc3m_dl4nlp/img/analogy_exercise.png)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy(['france', 'paris'], 'japan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a id='section10'></a>\n",
    "## Visualization (optional)\n",
    "Below we'll use T-SNE to visualize how our high-dimensional word vectors cluster together. T-SNE is used to project these vectors into two dimensions while preserving local stucture. Check out [this post from Christopher Olah](http://colah.github.io/posts/2014-10-Visualizing-MNIST/) to learn more about T-SNE and other ways to visualize high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# reduce size of the matrix to speed up the operations\n",
    "viz_words = 500\n",
    "start_ind = 1000\n",
    "end_ind = start_ind+viz_words\n",
    "small_ind = np.array([word2ind[word] for word in words[start_ind:end_ind]])\n",
    "small_word2ind = {word : i for i, word in enumerate(words[start_ind:end_ind])}\n",
    "small_matrix =  matrix[small_ind]\n",
    "\n",
    "# Project word embeddings to two-dimensions\n",
    "tsne = TSNE()\n",
    "embed_tsne = tsne.fit_transform(small_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "plt.scatter(x=embed_tsne[:,0], y=embed_tsne[:,1], c='steelblue')\n",
    "for i, word in enumerate(words[start_ind:end_ind]):\n",
    "    plt.annotate(word, (embed_tsne[small_word2ind[word], 0], embed_tsne[small_word2ind[word], 1]), alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='exercise10'></a>\n",
    "#### Exercise 10 (optional)\n",
    "> It would be interesting to color each point according to their semantic oreintation (e.g positive vs negative). For that, you could use the result obtained in Task2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
