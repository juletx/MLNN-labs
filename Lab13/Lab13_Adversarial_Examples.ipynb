{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 13.\n",
    "\n",
    "In this Lab we will focus on Adversarial Examples.\n",
    "\n",
    "\n",
    "The code in this notebook has been borrowed from the \"Craft Image Adversarial Samples with Tensorflow\" repository,  available in https://github.com/gongzhitaao/tensorflow-adversarial\n",
    "\n",
    "We will also use material from the book \"Hands-On Machine Learning with Scikit-Learn and TensorFlow. Concepts, Tools, and Techniques to Build Intelligent Systems\" by Aurélien Géron, that it is recommended as Bibliography of the course. http://shop.oreilly.com/product/0636920052289.do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by importing the python libraries required to solve the problems\n",
    "\n",
    "import os\n",
    "# supress tensorflow logging other than errors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import ModeKeys, Estimator\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import neat\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# from attacks.fgsm import fgsm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sets the seeds of the stochastic functions\n",
    "# to make the output of this notebook stable across runs\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # This line forces tensorflow to use the CPU instead of the GPU\n",
    "    # I did this because had problems with my CPU. You can set 'GPU': 1\n",
    "    config = tf.ConfigProto(device_count = {'GPU': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As a baseline dataset we use the the MNIST dataset that is loaded here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Loading mnist\n"
     ]
    }
   ],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "img_chas = 1\n",
    "input_shape = (img_rows, img_cols, img_chas)\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "# We import the MNIST dataset\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "print('\\nLoading mnist')\n",
    "\n",
    "# The train and test sets are defined \n",
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "y_train = mnist.train.labels.astype(\"int\")\n",
    "y_test = mnist.test.labels.astype(\"int\")\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "X_train = X_train.reshape(-1, img_rows, img_cols, img_chas)\n",
    "X_test = X_test.reshape(-1, img_rows, img_cols, img_chas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial examples (https://arxiv.org/pdf/1412.6572.pdf) are inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence.\n",
    "\n",
    "In this lab we will learn:\n",
    "\n",
    "1. What functions we can use to create adversarial examples.\n",
    "2. How to use the functions that create the adversarial examples.\n",
    "3. What is the effect of the adversarial example in the acccuracy of the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to create adversarial examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains the implementation of the  Fast Gradient Sign Method (FGSM). This method receives an observation (e.g., an MNIST image) and a model that outputs a correct classification of the image (e.g., a DNN classifier). FGSM outputs an image that is a pertubation of the original image, and makes the model to produce an incorrect classification. \n",
    "\n",
    "Several algorithms for creating adversarial examples exist, each of which operate in different ways to achieve their goal. \n",
    "FSGM finds adversarial perturbations which increase the value of the loss function (the one that we usually try to minimize during training).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model, x, eps=0.01, epochs=1, clip_min=0., clip_max=1.):\n",
    "    \"\"\"\n",
    "    Fast gradient sign method.\n",
    "\n",
    "    See https://arxiv.org/abs/1412.6572 and https://arxiv.org/abs/1607.02533\n",
    "    for details. This function implements the revised version, since the original FGSM\n",
    "    has label leaking problem (https://arxiv.org/abs/1611.01236).\n",
    "\n",
    "    :param model: A wrapper that returns the output as well as logits.\n",
    "    :param x: The input placeholder.\n",
    "    :param eps: The scale factor for noise.\n",
    "    :param epochs: The number of epoch to run.\n",
    "    :param clip_min: The minimum value in output.\n",
    "    :param clip_max: The maximum value in output.\n",
    "\n",
    "    :return: A tensor, contains adversarial samples for each input.\n",
    "    \"\"\"\n",
    "    \n",
    "    # x_adv will contain the adversarial example\n",
    "    x_adv = tf.identity(x)\n",
    "\n",
    "    # This is the classification given by the model to the original observation    \n",
    "    ybar = model(x_adv)\n",
    "    \n",
    "    # Number of possible values for the target class variable\n",
    "    ydim = ybar.get_shape().as_list()[1]\n",
    "    \n",
    "    # Classes for which the prediction is maximized \n",
    "    indices = tf.argmax(ybar, axis=1)\n",
    "    \n",
    "    \n",
    "    # If the dimension of the target variable is 1, then \n",
    "    # target is 0 or 1 according to whether the prob. is <0.5 or > 0.5\n",
    "    # If the dimension of the target variable is > 1, then \n",
    "    # then the target is the class that maximizes the probability\n",
    "    \n",
    "    target = tf.cond(\n",
    "        tf.equal(ydim, 1),\n",
    "        lambda: tf.nn.relu(tf.sign(ybar - 0.5)),\n",
    "        lambda: tf.one_hot(indices, ydim, on_value=1.0, off_value=0.0))\n",
    "    \n",
    "\n",
    "    # The loss_function is sigmoid or softmax according to the number\n",
    "    # of classes\n",
    "    if 1 == ydim:\n",
    "        loss_fn = tf.nn.sigmoid_cross_entropy_with_logits\n",
    "    else:\n",
    "        loss_fn = tf.nn.softmax_cross_entropy_with_logits_v2\n",
    "\n",
    "    # The scale factor is taken as positive    \n",
    "    eps = tf.abs(eps)\n",
    "\n",
    "    # Conditional check for the while (maximum number of epochs)\n",
    "    def _cond(x_adv, i):\n",
    "        return tf.less(i, epochs)\n",
    "\n",
    "    # This is the essential part of the FSGM procedure    \n",
    "    def _body(x_adv, i):\n",
    "        \n",
    "        # We get the prediction (and the logits) of the model\n",
    "        ybar, logits = model(x_adv, logits=True)\n",
    "        \n",
    "        # We also compute the probability for the target\n",
    "        loss = loss_fn(labels=target, logits=logits)\n",
    "        \n",
    "        # The gradient gives us the direction of maximum improvement\n",
    "        # of the loss function for each component (pixel) of the observation\n",
    "        dy_dx, = tf.gradients(loss, x_adv)\n",
    "        \n",
    "        # We use the gradient to \"move\" the adversarial example in the direction\n",
    "        # of the gradient (instead of going in the opposite direction to minimize loss)\n",
    "        x_adv = tf.stop_gradient(x_adv + eps*tf.sign(dy_dx))\n",
    "        \n",
    "        # Finally, the adversarial example is clipped \n",
    "        x_adv = tf.clip_by_value(x_adv, clip_min, clip_max)\n",
    "        return x_adv, i+1\n",
    "\n",
    "    x_adv, _ = tf.while_loop(_cond, _body, (x_adv, 0), back_prop=False,\n",
    "                             name='fgsm')\n",
    "    return x_adv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test FGSM, we need a model. In the following cell we define a convolutional network (similar to the ones we have practiced with in the lab before). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, logits=False, training=False):\n",
    "    \n",
    "    \n",
    "    conv0 = tf.layers.conv2d(x, filters=36, kernel_size=[3, 3],\n",
    "                             padding='same', name='conv0',\n",
    "                             activation=tf.nn.relu)\n",
    "    \n",
    "    pool0 = tf.layers.max_pooling2d(conv0, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool0')\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(pool0, filters=36,\n",
    "                             kernel_size=[3, 3], padding='same',\n",
    "                             name='conv1', activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool1')\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, filters=36,\n",
    "                             kernel_size=[3, 3], padding='same',\n",
    "                             name='conv1', activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool1')\n",
    "    \n",
    "    \n",
    "    flat = tf.layers.Flatten()(pool2)\n",
    "    \n",
    "    dense = tf.layers.dense(flat, units=576, activation=tf.nn.relu,\n",
    "                            name='dense')\n",
    "    \n",
    "    dropout = tf.layers.dropout(dense, rate=0.2, training=training,\n",
    "                                name='dropout')\n",
    "    \n",
    "    logits_ = tf.layers.dense(dropout, units=10, name='logits')\n",
    "    y = tf.nn.softmax(logits_, name='ybar')\n",
    "    if logits:\n",
    "        return y, logits_\n",
    "    return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining model loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network has been defined. We specify the pipeline to train it, including the loss function that we want to optimize (in this example, softmax_cross_entropy_with_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5d2160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5d2160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5d2160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5d2160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f014c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f014c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f014c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f014c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f014c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f014c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f014c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f014c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f0247630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f0247630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f0247630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f0247630>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "# Collect all tensorflow tensors into one \"enviroment\" to avoid\n",
    "# accidental overwriting.\n",
    "class Dummy:\n",
    "    pass\n",
    "env = Dummy()\n",
    "\n",
    "# We need a scope since the inference graph will be reused later\n",
    "with tf.variable_scope('model', reuse=tf.AUTO_REUSE):\n",
    "    env.x = tf.placeholder(tf.float32, (None, img_rows, img_cols,\n",
    "                                        img_chas), name='x')\n",
    "    env.y = tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "    env.training = tf.placeholder(bool, (), name='mode')\n",
    "\n",
    "    env.ybar, logits = model(env.x, logits=True,\n",
    "                             training=env.training)\n",
    "\n",
    "    z = tf.argmax(env.y, axis=1)\n",
    "    zbar = tf.argmax(env.ybar, axis=1)\n",
    "    count = tf.cast(tf.equal(z, zbar), tf.float32)\n",
    "    env.acc = tf.reduce_mean(count, name='acc')\n",
    "\n",
    "    xent = tf.nn.softmax_cross_entropy_with_logits_v2(labels=env.y,\n",
    "                                                   logits=logits)\n",
    "    env.loss = tf.reduce_mean(xent, name='loss')\n",
    "\n",
    "    env.optim = tf.train.AdamOptimizer().minimize(env.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use the model to find the adversarial samples, using the FGSM method, as defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4ffa9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4ffa9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4ffa9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4ffa9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4c43e80>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4c43e80>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4c43e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4c43e80>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f4f4e9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4f4e9e8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f4f4e9e8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4f4e9e8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4f4e9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4f4e9e8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4fa0550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4fa0550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4fa0550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f4fa0550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4fa0550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4fa0550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4fa0550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f4fa0550>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "# Note the reuse=True flag\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    env.x_adv = fgsm(model, env.x, epochs=12, eps=0.02)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the train set into a validation set and a  \"reduced\" train set. Later we will know what do we need the validation set for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shuffling training data\n"
     ]
    }
   ],
   "source": [
    "print('\\nShuffling training data')\n",
    "ind = np.random.permutation(X_train.shape[0])\n",
    "X_train, y_train = X_train[ind], y_train[ind]\n",
    "\n",
    "# split training/validation dataset\n",
    "validation_split = 0.1\n",
    "n_train = int(X_train.shape[0]*(1-validation_split))\n",
    "X_valid = X_train[n_train:]\n",
    "X_train = X_train[:n_train]\n",
    "y_valid = y_train[n_train:]\n",
    "y_train = y_train[:n_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow graph session is defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions _evaluate and _predict implement the training of the network and the predictio, respectively. They are a modular way to organize the learning process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate(X_data, y_data, env):\n",
    "    print('\\nEvaluating')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    loss, acc = 0, 0\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_loss, batch_acc = sess.run(\n",
    "            [env.loss, env.acc],\n",
    "            feed_dict={env.x: X_data[start:end],\n",
    "                       env.y: y_data[start:end],\n",
    "                       env.training: False})\n",
    "        loss += batch_loss*batch_size\n",
    "        acc += batch_acc*batch_size\n",
    "    loss /= n_sample\n",
    "    acc /= n_sample\n",
    "    print(' loss: {0:.4f} acc: {1:.4f}'.format(loss, acc))\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def _predict(X_data, env):\n",
    "    print('\\nPredicting')\n",
    "    n_sample = X_data.shape[0]\n",
    "    batch_size = 128\n",
    "    n_batch = int(np.ceil(n_sample/batch_size))\n",
    "    yval = np.empty((X_data.shape[0], n_classes))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        batch_y = sess.run(env.ybar, feed_dict={\n",
    "            env.x: X_data[start:end], env.training: False})\n",
    "        yval[start:end] = batch_y\n",
    "    print()\n",
    "    return yval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell the model is learned using the reduced train dataset and creating minibatches as we have done many times before. The validation set, that is NOT used for training, is used to estimate the quality of the model.\n",
    "\n",
    "The algorithm prints the accuracy and the loss function for this train data and also, at the end, for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "Epoch 1/2\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.4218 acc: 0.8679\n",
      "Epoch 2/2\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2303 acc: 0.9289\n",
      "\n",
      "Testing against clean data\n",
      "\n",
      "Evaluating\n",
      " loss: 0.2250 acc: 0.9426\n",
      "Model saved in file: /tmp/mnist_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining')\n",
    "n_sample = X_train.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "\n",
    "n_epoch = 2 # More epochs might be needed\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        sess.run(env.optim, feed_dict={env.x: X_train[start:end],\n",
    "                                       env.y: y_train[start:end],\n",
    "                                       env.training: True})\n",
    "    _evaluate(X_valid, y_valid, env)\n",
    "    \n",
    "\n",
    "print('\\nTesting against clean data')\n",
    "_evaluate(X_test, y_test, env)\n",
    "\n",
    "save_path = saver.save(sess, \"/tmp/mnist_model.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, in the results of the learning process, that the accuracy of the model was high, above 0.94 in my case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning adversarial examples using FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell the adversarial examples are created from the test data. Notice that tmp stores the output of the FGSM procedure as implemented within the environment env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crafting adversarial\n",
      " batch 12/79\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e42f17929917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     tmp = sess.run(env.x_adv, feed_dict={env.x: X_test[start:end],\n\u001b[1;32m     12\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                          env.training: False})\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX_adv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nSaving adversarial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('\\nCrafting adversarial')\n",
    "n_sample = X_test.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "n_epoch = 20\n",
    "X_adv = np.empty_like(X_test)\n",
    "for ind in range(n_batch):\n",
    "    print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "    start = ind*batch_size\n",
    "    end = min(n_sample, start+batch_size)\n",
    "    tmp = sess.run(env.x_adv, feed_dict={env.x: X_test[start:end],\n",
    "                                         env.y: y_test[start:end],\n",
    "                                         env.training: False})\n",
    "    X_adv[start:end] = tmp\n",
    "print('\\nSaving adversarial')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "np.save('data/ex_00.npy', X_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the accuracy of the model for the created adversarial examples (expect it to be low and compare with the accuracy values that we have previously obtained with the same model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTesting against adversarial data')\n",
    "_evaluate(X_adv, y_test, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell visualizes one adversarial example for each of the ten digits. Run the script and visualize the file img/ex_00.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      " batch 79/79\n",
      "\n",
      "Predicting\n",
      " batch 79/79\n",
      "Target 0\n",
      "Target 1\n",
      "Target 2\n",
      "Target 3\n",
      "Target 4\n",
      "Target 5\n",
      "Target 6\n",
      "Target 7\n",
      "Target 8\n",
      "Target 9\n",
      "\n",
      "Plotting results\n",
      "\n",
      "Saving figure\n"
     ]
    }
   ],
   "source": [
    "y1 = _predict(X_test, env)\n",
    "y2 = _predict(X_adv, env)\n",
    "\n",
    "z0 = np.argmax(y_test, axis=1)\n",
    "z1 = np.argmax(y1, axis=1)\n",
    "z2 = np.argmax(y2, axis=1)\n",
    "\n",
    "X_tmp = np.empty((10, 28, 28))\n",
    "y_tmp = np.empty((10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Target {0}'.format(i))\n",
    "    ind, = np.where(np.all([z0==i, z1==i, z2!=i], axis=0))\n",
    "    cur = np.random.choice(ind)\n",
    "\n",
    "    X_tmp[i] = np.squeeze(X_adv[cur])\n",
    "    y_tmp[i] = y2[cur]\n",
    "\n",
    "print('\\nPlotting results')\n",
    "fig = plt.figure(figsize=(10, 1.8))\n",
    "gs = gridspec.GridSpec(1, 10, wspace=0.1, hspace=0.1)\n",
    "\n",
    "label = np.argmax(y_tmp, axis=1)\n",
    "proba = np.max(y_tmp, axis=1)\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    ax.imshow(X_tmp[i], cmap='gray', interpolation='none')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('{0} ({1:.2f})'.format(label[i], proba[i]),\n",
    "                  fontsize=12)\n",
    "\n",
    "print('\\nSaving figure')\n",
    "gs.tight_layout(fig)\n",
    "os.makedirs('img', exist_ok=True)\n",
    "plt.savefig('img/ex_00.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x180 at 0x7FB5F4995278>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.open(\"img/ex_00.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "\n",
    "Modify the value of epsilon and observe the effect on the generated adversarial examples.\n",
    "Change the directory in which the images are saved to see the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5c52e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5c52e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5c52e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5eb5c52e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f17e8828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5f17e8828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5f17e8828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5f17e8828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5ea2e9630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5ea2e9630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5ea2e9630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2e9630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2e9630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2e9630>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5ea2f4860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5ea2f4860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5ea2f4860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5ea2f4860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2f4860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2f4860>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2f4860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5ea2f4860>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "# Note the reuse=True flag\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    env.x_adv = fgsm(model, env.x, epochs=12, eps=0.000013)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "Epoch 1/2\n",
      " batch 430/430\n",
      "Evaluating\n",
      " loss: 0.4987 acc: 0.8297\n",
      "Epoch 2/2\n",
      " batch 430/430\n",
      "Evaluating\n",
      " loss: 0.2836 acc: 0.9059\n",
      "\n",
      "Testing against clean data\n",
      "\n",
      "Evaluating\n",
      " loss: 0.2673 acc: 0.9252\n",
      "Model saved in file: /tmp/mnist_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining')\n",
    "n_sample = X_train.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "\n",
    "n_epoch = 2 # More epochs might be needed\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        sess.run(env.optim, feed_dict={env.x: X_train[start:end],\n",
    "                                       env.y: y_train[start:end],\n",
    "                                       env.training: True})\n",
    "    _evaluate(X_valid, y_valid, env)\n",
    "    \n",
    "\n",
    "print('\\nTesting against clean data')\n",
    "_evaluate(X_test, y_test, env)\n",
    "\n",
    "save_path = saver.save(sess, \"/tmp/mnist_model.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crafting adversarial\n",
      " batch 79/79\n",
      "Saving adversarial\n"
     ]
    }
   ],
   "source": [
    "print('\\nCrafting adversarial')\n",
    "n_sample = X_test.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "n_epoch = 20\n",
    "X_adv = np.empty_like(X_test)\n",
    "for ind in range(n_batch):\n",
    "    print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "    start = ind*batch_size\n",
    "    end = min(n_sample, start+batch_size)\n",
    "    tmp = sess.run(env.x_adv, feed_dict={env.x: X_test[start:end],\n",
    "                                         env.y: y_test[start:end],\n",
    "                                         env.training: False})\n",
    "    X_adv[start:end] = tmp\n",
    "print('\\nSaving adversarial')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "np.save('data/ex_01.npy', X_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing against adversarial data\n",
      "\n",
      "Evaluating\n",
      " loss: 0.4638 acc: 0.8161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46383741760253905, 0.8161)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nTesting against adversarial data')\n",
    "_evaluate(X_adv, y_test, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      " batch 79/79\n",
      "\n",
      "Predicting\n",
      " batch 79/79\n",
      "Target 0\n",
      "Target 1\n",
      "Target 2\n",
      "Target 3\n",
      "Target 4\n",
      "Target 5\n",
      "Target 6\n",
      "Target 7\n",
      "Target 8\n",
      "Target 9\n",
      "\n",
      "Plotting results\n",
      "\n",
      "Saving figure\n"
     ]
    }
   ],
   "source": [
    "y1 = _predict(X_test, env)\n",
    "y2 = _predict(X_adv, env)\n",
    "\n",
    "z0 = np.argmax(y_test, axis=1)\n",
    "z1 = np.argmax(y1, axis=1)\n",
    "z2 = np.argmax(y2, axis=1)\n",
    "\n",
    "X_tmp = np.empty((10, 28, 28))\n",
    "y_tmp = np.empty((10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Target {0}'.format(i))\n",
    "    ind, = np.where(np.all([z0==i, z1==i, z2!=i], axis=0))\n",
    "    cur = np.random.choice(ind)\n",
    "\n",
    "    X_tmp[i] = np.squeeze(X_adv[cur])\n",
    "    y_tmp[i] = y2[cur]\n",
    "\n",
    "print('\\nPlotting results')\n",
    "fig = plt.figure(figsize=(10, 1.8))\n",
    "gs = gridspec.GridSpec(1, 10, wspace=0.1, hspace=0.1)\n",
    "\n",
    "label = np.argmax(y_tmp, axis=1)\n",
    "proba = np.max(y_tmp, axis=1)\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    ax.imshow(X_tmp[i], cmap='gray', interpolation='none')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('{0} ({1:.2f})'.format(label[i], proba[i]),\n",
    "                  fontsize=12)\n",
    "\n",
    "print('\\nSaving figure')\n",
    "gs.tight_layout(fig)\n",
    "os.makedirs(\"img\", exist_ok=True)\n",
    "plt.savefig(\"img\" + '/ex_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x180 at 0x7FB5EB5C53C8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"img/ex_00.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x180 at 0x7FB5EB5C5390>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"img/ex_01.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 \n",
    "\n",
    " 2.1) Reuse the CNN and the code in the following cell to generate adversarial examples for the fashion dataset.\n",
    " \n",
    " 2.2) The effectiveness of adversarial learning is totally dependent on the quality of the model used for classification. Therefore, if the accuracy of the trained model is not very high (this can happen, as the Fashion MNIST problem is harder than the MINST), modify the model (possibly by adding the capacity of the model) and/or increase the number of training epochs.\n",
    " \n",
    " 2.3) Copy and modify the code that was previously used to visualize and save the adversarial examples of the fashion dataset (save them with a different name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist, fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_And_Normalize_Image_Dataset(db_name='mnist', max_train_samples = 10000,max_test_samples = 10000):\n",
    "\n",
    "    if db_name=='mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()               \n",
    "    elif db_name=='fashion':\n",
    "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()        \n",
    "        \n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    \n",
    "    one_hot_y_train = np.zeros((y_train.size, y_train.max()+1))\n",
    "    one_hot_y_train[np.arange(y_train.size),y_train] = 1\n",
    "    \n",
    "    one_hot_y_test = np.zeros((y_test.size, y_test.max()+1))\n",
    "    one_hot_y_test[np.arange(y_test.size),y_test] = 1\n",
    "\n",
    "\n",
    "    return (x_train, one_hot_y_train), (x_test, one_hot_y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "(5500, 28, 28, 1) (49500, 28, 28, 1) (10000, 28, 28, 1) (5500, 10) (49500, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = Read_And_Normalize_Image_Dataset(db_name='fashion', max_train_samples = 10000, max_test_samples = 10000)\n",
    "#fashion_train = np.reshape(fashion_train, (-1, 784))\n",
    "#fashion_test = np.reshape(fashion_test, (-1, 784))\n",
    "# The train and test sets are defined \n",
    "\n",
    "X_train_fashion = X_train_fashion.reshape(-1, img_rows, img_cols, img_chas)\n",
    "X_test_fashion  = X_test_fashion.reshape(-1, img_rows, img_cols, img_chas)\n",
    "\n",
    "y_train_fashion =  y_train_fashion.astype(\"int\")\n",
    "y_test_fashion =  y_test_fashion.astype(\"int\")\n",
    "\n",
    "print('Shuffling training data')\n",
    "ind = np.random.permutation(X_train.shape[0])\n",
    "X_train_fashion, y_train_fashion = X_train_fashion[ind], y_train_fashion[ind]\n",
    "\n",
    "# split training/validation dataset\n",
    "validation_split = 0.1\n",
    "n_train = int(X_train_fashion.shape[0]*(1-validation_split))\n",
    "X_valid_fashion = X_train_fashion[n_train:]\n",
    "X_train_fashion = X_train_fashion[:n_train]\n",
    "y_valid_fashion = y_train_fashion[n_train:]\n",
    "y_train_fashion = y_train_fashion[:n_train]\n",
    "\n",
    "print(X_valid_fashion.shape, X_train_fashion.shape, X_test_fashion.shape, y_valid_fashion.shape, y_train_fashion.shape, y_test_fashion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fashion(x, logits=False, training=False):\n",
    "    conv0 = tf.layers.conv2d(x, filters=36, kernel_size=[3, 3],\n",
    "                             padding='same', name='conv0',\n",
    "                             activation=tf.nn.relu)\n",
    "    \n",
    "    pool0 = tf.layers.max_pooling2d(conv0, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool0')\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(pool0, filters=36,\n",
    "                             kernel_size=[3, 3], padding='same',\n",
    "                             name='conv1', activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(conv1, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool1')\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, filters=36,\n",
    "                             kernel_size=[3, 3], padding='same',\n",
    "                             name='conv1', activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(conv2, pool_size=[2, 2],\n",
    "                                    strides=2, name='pool1')\n",
    "    \n",
    "    \n",
    "    flat = tf.layers.Flatten()(pool2)\n",
    "    \n",
    "    dense = tf.layers.dense(flat, units=576, activation=tf.nn.relu,\n",
    "                            name='dense')\n",
    "    \n",
    "    dropout = tf.layers.dropout(dense, rate=0.2, training=training,\n",
    "                                name='dropout')\n",
    "    \n",
    "    logits_ = tf.layers.dense(dropout, units=10, name='logits')\n",
    "    y = tf.nn.softmax(logits_, name='ybar')\n",
    "    if logits:\n",
    "        return y, logits_\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e69ea860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e69ea860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e69ea860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e69ea860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e69ea860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e69ea860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e69ea860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e69ea860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb6949c26d8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb6949c26d8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb6949c26d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb6949c26d8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d7969400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d7969400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d7969400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d7969400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d7969400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d7969400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d7969400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d7969400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d796dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d796dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d796dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5d796dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d796dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d796dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d796dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5d796dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e67af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb5e67af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e67af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fb5e67af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5e67af4e0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb5e67af4e0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5e67af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x7fb5e67af4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fb5e67af4e0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "# Note the reuse=True flag\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    env.x_adv = fgsm(model_fashion, env.x, epochs=12, eps=0.000013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "Epoch 1/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.4026 acc: 0.8572\n",
      "Epoch 2/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.3347 acc: 0.8815\n",
      "Epoch 3/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2887 acc: 0.8979\n",
      "Epoch 4/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2691 acc: 0.9037\n",
      "Epoch 5/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2595 acc: 0.9054\n",
      "Epoch 6/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2539 acc: 0.9072\n",
      "Epoch 7/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2483 acc: 0.9101\n",
      "Epoch 8/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2531 acc: 0.9081\n",
      "Epoch 9/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2524 acc: 0.9085\n",
      "Epoch 10/10\n",
      " batch 387/387\n",
      "Evaluating\n",
      " loss: 0.2598 acc: 0.9074\n",
      "\n",
      "Testing against clean data\n",
      "\n",
      "Evaluating\n",
      " loss: 0.3026 acc: 0.9032\n",
      "Model saved in file: /tmp/fahsion_mnist_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining')\n",
    "n_sample = X_train_fashion.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "\n",
    "n_epoch = 10 # More epochs might be needed\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        sess.run(env.optim, feed_dict={env.x: X_train_fashion[start:end],\n",
    "                                       env.y: y_train_fashion[start:end],\n",
    "                                       env.training: True})\n",
    "    _evaluate(X_valid_fashion, y_valid_fashion, env)\n",
    "    \n",
    "\n",
    "print('\\nTesting against clean data')\n",
    "_evaluate(X_test_fashion, y_test_fashion, env)\n",
    "\n",
    "save_path = saver.save(sess, \"/tmp/fahsion_mnist_model.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crafting adversarial\n",
      " batch 79/79\n",
      "Saving adversarial\n"
     ]
    }
   ],
   "source": [
    "print('\\nCrafting adversarial')\n",
    "n_sample = X_test_fashion.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "n_epoch = 20\n",
    "X_adv_fashion = np.empty_like(X_test_fashion)\n",
    "for ind in range(n_batch):\n",
    "    print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "    start = ind*batch_size\n",
    "    end = min(n_sample, start+batch_size)\n",
    "    tmp = sess.run(env.x_adv, feed_dict={env.x: X_test_fashion[start:end],\n",
    "                                         env.y: y_test_fashion[start:end],\n",
    "                                         env.training: False})\n",
    "    X_adv_fashion[start:end] = tmp\n",
    "print('\\nSaving adversarial')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "np.save('data/ex_02.npy', X_adv_fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing against adversarial data\n",
      "\n",
      "Evaluating\n",
      " loss: 0.3019 acc: 0.9027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.30193941822052, 0.9027)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nTesting against adversarial data')\n",
    "_evaluate(X_adv_fashion, y_test_fashion, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting\n",
      " batch 79/79\n",
      "\n",
      "Predicting\n",
      " batch 79/79\n",
      "Target 0\n",
      "Target 1\n",
      "No examples classified in this class\n",
      "Target 2\n",
      "Target 3\n",
      "Target 4\n",
      "Target 5\n",
      "No examples classified in this class\n",
      "Target 6\n",
      "Target 7\n",
      "No examples classified in this class\n",
      "Target 8\n",
      "No examples classified in this class\n",
      "Target 9\n",
      "\n",
      "Plotting results\n",
      "\n",
      "Saving figure\n"
     ]
    }
   ],
   "source": [
    "y1 = _predict(X_test_fashion, env)\n",
    "y2 = _predict(X_adv_fashion, env)\n",
    "\n",
    "z0 = np.argmax(y_test_fashion, axis=1)\n",
    "z1 = np.argmax(y1, axis=1)\n",
    "z2 = np.argmax(y2, axis=1)\n",
    "\n",
    "X_tmp = np.empty((10, 28, 28))\n",
    "y_tmp = np.empty((10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Target {0}'.format(i))\n",
    "    ind, = np.where(np.all([z0==i, z1==i, z2!=i], axis=0))\n",
    "    if ind.shape[0] > 0:\n",
    "        cur = np.random.choice(ind)\n",
    "\n",
    "        X_tmp[i] = np.squeeze(X_adv_fashion[cur])\n",
    "        y_tmp[i] = y2[cur]\n",
    "    else:\n",
    "        print(\"No examples classified in this class\")\n",
    "\n",
    "print('\\nPlotting results')\n",
    "fig = plt.figure(figsize=(10, 1.8))\n",
    "gs = gridspec.GridSpec(1, 10, wspace=0.1, hspace=0.1)\n",
    "\n",
    "label = np.argmax(y_tmp, axis=1)\n",
    "proba = np.max(y_tmp, axis=1)\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    ax.imshow(X_tmp[i], cmap='gray', interpolation='none')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('{0} ({1:.2f})'.format(label[i], proba[i]),\n",
    "                  fontsize=12)\n",
    "\n",
    "print('\\nSaving figure')\n",
    "gs.tight_layout(fig)\n",
    "os.makedirs('img_fashion', exist_ok=True)\n",
    "plt.savefig('img_fashion/ex_00.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the classes in Fahsion MNIST have the following meanings:\n",
    "\n",
    "| Label | Description |\n",
    "| :---: |    :---:    |\n",
    "|   0   | T-shirt/top |\n",
    "|   1   |   Trouser   |\n",
    "|   2   |   Pullover  |\n",
    "|   3   |    Dress    |\n",
    "|   4   |    Coat     |\n",
    "|   5   |    Sandal   |\n",
    "|   6   |    Shirt    |\n",
    "|   7   |   Sneaker   |\n",
    "|   8   |     Bag     |\n",
    "|   9   |  Ankle boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1000x180 at 0x7FB5D7767B38>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"img_fashion/ex_00.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "\n",
    "Download the github directory https://github.com/gongzhitaao/tensorflow-adversarial. In the folder \"attacks\" you will find other attacks in addition to fgsm\n",
    "\n",
    "3.1) Use the \"Jacobian-based Saliency Map Approach\" (jsma, available in saliency_map.py) to create adversarial examples using the MNIST dataset and the model previously trained. These examples should get \"1\" as prediction from the model. \n",
    "\n",
    "3.2) Complete the rest of the cells as necessary to plot the adversarial examples.\n",
    "\n",
    "3.3) Inspect the file img/adv_examples_ones.png.\n",
    "\n",
    "\n",
    "Suggestion: Copy the content of saliency_map.py to a new cell and modify the \"env\" environment so you could learn the adversarial examples in a similar way we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsma(model, x, y=None, epochs=1, eps=1.0, k=1, clip_min=0.0, clip_max=1.0,\n",
    "         score_fn=lambda t, o: t * tf.abs(o)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all tensorflow tensors into one \"enviroment\" to avoid\n",
    "# accidental overwriting.\n",
    "class Dummy:\n",
    "    pass\n",
    "env = Dummy()\n",
    "\n",
    "# We need a scope since the inference graph will be reused later\n",
    "with tf.variable_scope('model', reuse=tf.AUTO_REUSE):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the reuse=True flag\n",
    "with tf.variable_scope('model', reuse=True):\n",
    "    env.x_adv =     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\nTraining')\n",
    "n_sample = X_train.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "\n",
    "n_epoch = 2 # More epochs might be needed\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch {0}/{1}'.format(epoch+1, n_epoch))\n",
    "    for ind in range(n_batch):\n",
    "        print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "        start = ind*batch_size\n",
    "        end = min(n_sample, start+batch_size)\n",
    "        sess.run(env.optim, feed_dict={env.x: X_train[start:end],\n",
    "                                       env.y: y_train[start:end],\n",
    "                                       env.training: True})\n",
    "    _evaluate(X_valid, y_valid, env)\n",
    "    \n",
    "\n",
    "print('\\nTesting against clean data')\n",
    "_evaluate(X_test, y_test, env)\n",
    "\n",
    "save_path = saver.save(sess, \"/tmp/mnist_model.ckpt\")\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('\\nCrafting adversarial')\n",
    "n_sample = X_test.shape[0]\n",
    "batch_size = 128\n",
    "n_batch = int(np.ceil(n_sample/batch_size))\n",
    "n_epoch = 20\n",
    "X_adv = np.empty_like(X_test)\n",
    "for ind in range(n_batch):\n",
    "    print(' batch {0}/{1}'.format(ind+1, n_batch), end='\\r')\n",
    "    start = ind*batch_size\n",
    "    end = min(n_sample, start+batch_size)\n",
    "    tmp = sess.run(env.x_adv, feed_dict={env.x: X_test[start:end],\n",
    "                                         env.y: y_test[start:end],\n",
    "                                         env.training: False})\n",
    "    X_adv[start:end] = tmp\n",
    "print('\\nSaving adversarial')\n",
    "os.makedirs('data', exist_ok=True)\n",
    "np.save('data/ex_00.npy', X_adv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTesting against adversarial data')\n",
    "_evaluate(X_adv, y_test, env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = _predict(X_test, env)\n",
    "y2 = _predict(X_adv, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = np.argmax(y_test, axis=1)\n",
    "z1 = np.argmax(y1, axis=1)\n",
    "z2 = np.argmax(y2, axis=1)\n",
    "\n",
    "X_tmp = np.empty((10, 28, 28))\n",
    "y_tmp = np.empty((10, 10))\n",
    "fig = plt.figure(figsize=(10, 1.8))\n",
    "for i in range(10):\n",
    "    ind, = np.where(np.all([z0==i, z1==i, z2==1], axis=0))\n",
    "    cur = np.random.choice(ind)\n",
    "    X_tmp[i] = np.squeeze(X_adv[cur])\n",
    "    y_tmp[i] = y2[cur]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(np.argmax(y1, axis=1), return_counts=True))\n",
    "print(np.unique(np.argmax(y2, axis=1), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPlotting results')\n",
    "fig = plt.figure(figsize=(10, 1.8))\n",
    "gs = gridspec.GridSpec(1, 10, wspace=0.1, hspace=0.1)\n",
    "\n",
    "label = np.argmax(y_tmp, axis=1)\n",
    "proba = np.max(y_tmp, axis=1)\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    ax.imshow(X_tmp[i], cmap='gray', interpolation='none', vmin=0, vmax=0.005)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('{0} ({1:.2f})'.format(label[i], proba[i]),\n",
    "                  fontsize=12)\n",
    "\n",
    "print('\\nSaving figure')\n",
    "gs.tight_layout(fig)\n",
    "os.makedirs('img28', exist_ok=True)\n",
    "plt.savefig('img28/adv_examples_ones.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
